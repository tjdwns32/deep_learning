{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjdwn\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version :  1.10.0\n",
      "<common.nlp.data_loader.N2NTextData object at 0x0000026C55318F28>\n",
      "WARNING:tensorflow:From C:\\Users\\tjdwn\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:430: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From C:\\Users\\tjdwn\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n",
      "model/emb:0\n",
      "model/birnn/fw/gru_cell/gates/kernel:0\n",
      "model/birnn/fw/gru_cell/gates/bias:0\n",
      "model/birnn/fw/gru_cell/candidate/kernel:0\n",
      "model/birnn/fw/gru_cell/candidate/bias:0\n",
      "model/birnn/bw/gru_cell/gates/kernel:0\n",
      "model/birnn/bw/gru_cell/gates/bias:0\n",
      "model/birnn/bw/gru_cell/candidate/kernel:0\n",
      "model/birnn/bw/gru_cell/candidate/bias:0\n",
      "model/Rnn2Target/weights:0\n",
      "model/Rnn2Target/biases:0\n",
      "WARNING:tensorflow:From <ipython-input-1-fcc8eaa1c61d>:187: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "INFO:tensorflow:Restoring parameters from ./trained_models\\model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Saving checkpoint to path ./trained_models\\model.ckpt\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:model/global_step/sec: 0\n",
      "Epoch =   1 Step =       1 loss = 2.565\n",
      "Epoch =   1 Step =       2 loss = 2.463\n",
      "Epoch =   2 Step =       3 loss = 2.264\n",
      "Epoch =   2 Step =       4 loss = 1.978\n",
      "Epoch =   3 Step =       5 loss = 1.880\n",
      "Epoch =   3 Step =       6 loss = 1.789\n",
      "Epoch =   4 Step =       7 loss = 1.683\n",
      "Epoch =   4 Step =       8 loss = 1.603\n",
      "Epoch =   5 Step =       9 loss = 1.546\n",
      "Epoch =   5 Step =      10 loss = 1.497\n",
      "Epoch =  10 Step =      20 loss = 1.180\n",
      "Epoch =  15 Step =      30 loss = 0.989\n",
      "Epoch =  20 Step =      40 loss = 0.847\n",
      "Epoch =  25 Step =      50 loss = 0.734\n",
      "Epoch =  30 Step =      60 loss = 0.644\n",
      "Epoch =  35 Step =      70 loss = 0.572\n",
      "Epoch =  40 Step =      80 loss = 0.513\n",
      "Epoch =  45 Step =      90 loss = 0.465\n",
      "Epoch =  50 Step =     100 loss = 0.424\n",
      "Epoch =  55 Step =     110 loss = 0.390\n",
      "Epoch =  60 Step =     120 loss = 0.360\n",
      "Epoch =  65 Step =     130 loss = 0.335\n",
      "Epoch =  70 Step =     140 loss = 0.313\n",
      "Epoch =  75 Step =     150 loss = 0.294\n",
      "Epoch =  80 Step =     160 loss = 0.277\n",
      "Epoch =  85 Step =     170 loss = 0.262\n",
      "Epoch =  90 Step =     180 loss = 0.248\n",
      "Epoch =  95 Step =     190 loss = 0.235\n",
      "Epoch = 100 Step =     200 loss = 0.224\n",
      "Epoch = 105 Step =     210 loss = 0.214\n",
      "Epoch = 110 Step =     220 loss = 0.205\n",
      "Epoch = 115 Step =     230 loss = 0.196\n",
      "Epoch = 120 Step =     240 loss = 0.189\n",
      "Epoch = 125 Step =     250 loss = 0.181\n",
      "Epoch = 130 Step =     260 loss = 0.175\n",
      "Epoch = 135 Step =     270 loss = 0.168\n",
      "Epoch = 140 Step =     280 loss = 0.163\n",
      "Epoch = 145 Step =     290 loss = 0.157\n",
      "Epoch = 150 Step =     300 loss = 0.152\n",
      "Epoch = 155 Step =     310 loss = 0.148\n",
      "Epoch = 160 Step =     320 loss = 0.143\n",
      "Epoch = 165 Step =     330 loss = 0.139\n",
      "Epoch = 170 Step =     340 loss = 0.135\n",
      "Epoch = 175 Step =     350 loss = 0.131\n",
      "Epoch = 180 Step =     360 loss = 0.128\n",
      "Epoch = 185 Step =     370 loss = 0.124\n",
      "Epoch = 190 Step =     380 loss = 0.121\n",
      "Epoch = 195 Step =     390 loss = 0.118\n",
      "Epoch = 200 Step =     400 loss = 0.115\n",
      "Epoch = 205 Step =     410 loss = 0.112\n",
      "Epoch = 210 Step =     420 loss = 0.110\n",
      "Epoch = 215 Step =     430 loss = 0.107\n",
      "Epoch = 220 Step =     440 loss = 0.105\n",
      "Epoch = 225 Step =     450 loss = 0.103\n",
      "Epoch = 230 Step =     460 loss = 0.101\n",
      "Epoch = 235 Step =     470 loss = 0.098\n",
      "Epoch = 240 Step =     480 loss = 0.096\n",
      "Epoch = 245 Step =     490 loss = 0.095\n",
      "Epoch = 250 Step =     500 loss = 0.093\n",
      "Epoch = 255 Step =     510 loss = 0.091\n",
      "Epoch = 260 Step =     520 loss = 0.089\n",
      "Epoch = 265 Step =     530 loss = 0.088\n",
      "Epoch = 270 Step =     540 loss = 0.086\n",
      "Epoch = 275 Step =     550 loss = 0.085\n",
      "Epoch = 280 Step =     560 loss = 0.083\n",
      "Epoch = 285 Step =     570 loss = 0.082\n",
      "Epoch = 290 Step =     580 loss = 0.080\n",
      "Epoch = 295 Step =     590 loss = 0.079\n",
      "Epoch = 300 Step =     600 loss = 0.078\n",
      "Epoch = 305 Step =     610 loss = 0.076\n",
      "Epoch = 310 Step =     620 loss = 0.075\n",
      "Epoch = 315 Step =     630 loss = 0.074\n",
      "Epoch = 320 Step =     640 loss = 0.073\n",
      "Epoch = 325 Step =     650 loss = 0.072\n",
      "Epoch = 330 Step =     660 loss = 0.071\n",
      "Epoch = 335 Step =     670 loss = 0.070\n",
      "Epoch = 340 Step =     680 loss = 0.069\n",
      "Epoch = 345 Step =     690 loss = 0.068\n",
      "Epoch = 350 Step =     700 loss = 0.067\n",
      "Epoch = 355 Step =     710 loss = 0.066\n",
      "Epoch = 360 Step =     720 loss = 0.065\n",
      "Epoch = 365 Step =     730 loss = 0.064\n",
      "Epoch = 370 Step =     740 loss = 0.063\n",
      "Epoch = 375 Step =     750 loss = 0.063\n",
      "Epoch = 380 Step =     760 loss = 0.062\n",
      "Epoch = 385 Step =     770 loss = 0.061\n",
      "Epoch = 390 Step =     780 loss = 0.060\n",
      "Epoch = 395 Step =     790 loss = 0.059\n",
      "Epoch = 400 Step =     800 loss = 0.059\n",
      "Epoch = 405 Step =     810 loss = 0.058\n",
      "Epoch = 410 Step =     820 loss = 0.057\n",
      "Epoch = 415 Step =     830 loss = 0.057\n",
      "Epoch = 420 Step =     840 loss = 0.056\n",
      "Epoch = 425 Step =     850 loss = 0.055\n",
      "Epoch = 430 Step =     860 loss = 0.055\n",
      "Epoch = 435 Step =     870 loss = 0.054\n",
      "Epoch = 440 Step =     880 loss = 0.053\n",
      "Epoch = 445 Step =     890 loss = 0.053\n",
      "Epoch = 450 Step =     900 loss = 0.052\n",
      "Epoch = 455 Step =     910 loss = 0.052\n",
      "Epoch = 460 Step =     920 loss = 0.051\n",
      "Epoch = 465 Step =     930 loss = 0.051\n",
      "Epoch = 470 Step =     940 loss = 0.050\n",
      "Epoch = 475 Step =     950 loss = 0.050\n",
      "Epoch = 480 Step =     960 loss = 0.049\n",
      "Epoch = 485 Step =     970 loss = 0.049\n",
      "Epoch = 490 Step =     980 loss = 0.048\n",
      "Epoch = 495 Step =     990 loss = 0.048\n",
      "Epoch = 500 Step =    1000 loss = 0.047\n",
      "Epoch = 505 Step =    1010 loss = 0.047\n",
      "Epoch = 510 Step =    1020 loss = 0.046\n",
      "Epoch = 515 Step =    1030 loss = 0.046\n",
      "Epoch = 520 Step =    1040 loss = 0.045\n",
      "Epoch = 525 Step =    1050 loss = 0.045\n",
      "Epoch = 530 Step =    1060 loss = 0.045\n",
      "Epoch = 535 Step =    1070 loss = 0.044\n",
      "Epoch = 540 Step =    1080 loss = 0.044\n",
      "Epoch = 545 Step =    1090 loss = 0.043\n",
      "Epoch = 550 Step =    1100 loss = 0.043\n",
      "Epoch = 555 Step =    1110 loss = 0.043\n",
      "Epoch = 560 Step =    1120 loss = 0.042\n",
      "Epoch = 565 Step =    1130 loss = 0.042\n",
      "Epoch = 570 Step =    1140 loss = 0.042\n",
      "Epoch = 575 Step =    1150 loss = 0.041\n",
      "Epoch = 580 Step =    1160 loss = 0.041\n",
      "Epoch = 585 Step =    1170 loss = 0.041\n",
      "Epoch = 590 Step =    1180 loss = 0.040\n",
      "Epoch = 595 Step =    1190 loss = 0.040\n",
      "Epoch = 600 Step =    1200 loss = 0.040\n",
      "Training is done.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_models\\model.ckpt-0\n",
      "INFO:tensorflow:Froze 11 variables.\n",
      "INFO:tensorflow:Converted 11 variables to const ops.\n",
      "1683 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Named Entity Recognition \n",
    "\n",
    "        Author : Sangkeun Jung (2017)\n",
    "        - using Tensorflow\n",
    "\"\"\"\n",
    "\n",
    "import sys, os, inspect\n",
    "\n",
    "# add common to path\n",
    "from pathlib import Path\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "common_path = str(Path(currentdir).parent.parent)\n",
    "sys.path.append( common_path )\n",
    "\n",
    "from common.nlp.vocab import Vocab\n",
    "from common.nlp.data_loader import N2NTextData\n",
    "from common.nlp.converter import N2NConverter\n",
    "\n",
    "from dataset import NERDataset\n",
    "from dataset import load_data\n",
    "from common.ml.hparams import HParams\n",
    "\n",
    "import numpy as np\n",
    "import copy \n",
    "import time \n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn\n",
    "from tensorflow.contrib.layers.python.layers import linear\n",
    "from tensorflow.python.ops import variable_scope\n",
    "from tensorflow.contrib.seq2seq import sequence_loss#sequence의 loss의 평균값을 구할 수있음\n",
    "\n",
    "from common.ml.tf.deploy import freeze_graph\n",
    "\n",
    "\n",
    "\n",
    "print( \"Tensorflow Version : \", tf.__version__)\n",
    "\n",
    "class NER():\n",
    "    def __init__(self, hps, mode=\"train\"):\n",
    "        self.hps = hps\n",
    "        self.x = tf.placeholder(tf.int32,   [None, hps.num_steps], name=\"pl_tokens\")\n",
    "        self.y = tf.placeholder(tf.int32,   [None, hps.num_steps], name=\"pl_target\")\n",
    "        self.w = tf.placeholder(tf.float32, [None, hps.num_steps], name=\"pl_weight\")\n",
    "        self.keep_prob = tf.placeholder(tf.float32, [], name=\"pl_keep_prob\")\n",
    "\n",
    "        ### 4 blocks ###\n",
    "        # 1) embedding\n",
    "        # 2) dropout on input embedding\n",
    "        # 3) sentence encoding using rnn\n",
    "        # 4) bidirectional rnn's output to target classes\n",
    "        # 5) loss calcaulation\n",
    "\n",
    "        def _embedding(x):\n",
    "            # character embedding \n",
    "            shape       = [hps.vocab_size, hps.emb_size]\n",
    "            initializer = tf.initializers.variance_scaling(distribution=\"uniform\", dtype=tf.float32)\n",
    "            emb_mat     = tf.get_variable(\"emb\", shape, initializer=initializer, dtype=tf.float32)\n",
    "            input_emb   = tf.nn.embedding_lookup(emb_mat, x)   # [batch_size, sent_len, emb_dim]\n",
    "\n",
    "            # split input_emb -> num_steps\n",
    "            step_inputs = tf.unstack(input_emb, axis=1)\n",
    "            return step_inputs\n",
    "\n",
    "        def _sequence_dropout(step_inputs, keep_prob):\n",
    "            # apply dropout to each input\n",
    "            # input : a list of input tensor which shape is [None, input_dim]\n",
    "            with tf.name_scope('sequence_dropout') as scope:\n",
    "                step_outputs = []\n",
    "                for t, input in enumerate(step_inputs):\n",
    "                    step_outputs.append( tf.nn.dropout(input, keep_prob) )\n",
    "            return step_outputs\n",
    "\n",
    "        def sequence_encoding_n2n(step_inputs, seq_length, cell_size):\n",
    "            # birnn based N2N encoding and output\n",
    "            f_rnn_cell = tf.contrib.rnn.GRUCell(cell_size, reuse=False)\n",
    "            b_rnn_cell = tf.contrib.rnn.GRUCell(cell_size, reuse=False)\n",
    "            _inputs    = tf.stack(step_inputs, axis=1)\n",
    "\n",
    "            # step_inputs = a list of [batch_size, emb_dim]\n",
    "            # input = [batch_size, num_step, emb_dim]\n",
    "            # np.stack( [a,b,c,] )\n",
    "            outputs, states, = tf.nn.bidirectional_dynamic_rnn( f_rnn_cell,\n",
    "                                                                b_rnn_cell,\n",
    "                                                                _inputs,\n",
    "                                                                sequence_length=tf.cast(seq_length, tf.int64),\n",
    "                                                                time_major=False,\n",
    "                                                                dtype=tf.float32,\n",
    "                                                                scope='birnn',\n",
    "                                                            )\n",
    "            output_fw, output_bw = outputs\n",
    "            states_fw, states_bw = states \n",
    "\n",
    "            output       = tf.concat([output_fw, output_bw], 2)\n",
    "            step_outputs = tf.unstack(output, axis=1)\n",
    "\n",
    "            final_state  = tf.concat([states_fw, states_bw], 1)\n",
    "            return step_outputs # a list of [batch_size, enc_dim]\n",
    "\n",
    "        def _to_class_n2n(step_inputs, num_class):\n",
    "            T = len(step_inputs)\n",
    "            step_output_logits = []\n",
    "            for t in range(T):\n",
    "                # encoder to linear(map)\n",
    "                out = step_inputs[t]\n",
    "                if t==0: out = linear(out, num_class, scope=\"Rnn2Target\")\n",
    "                else:    out = linear(out, num_class, scope=\"Rnn2Target\", reuse=True)\n",
    "                step_output_logits.append(out)\n",
    "            return step_output_logits\n",
    "\n",
    "        def _loss(step_outputs, step_refs, weights):\n",
    "            # step_outputs : a list of [batch_size, num_class] float32 - unscaled logits\n",
    "            # step_refs    : [batch_size, num_steps] int32\n",
    "            # weights      : [batch_size, num_steps] float32\n",
    "            # calculate sequence wise loss function using cross-entropy\n",
    "            _batch_output_logits = tf.stack(step_outputs, axis=1)\n",
    "            loss = sequence_loss(\n",
    "                                    logits=_batch_output_logits,        \n",
    "                                    targets=step_refs,\n",
    "                                    weights=weights\n",
    "                                )\n",
    "            return loss\n",
    "        \n",
    "        seq_length    = tf.reduce_sum(self.w, 1) # [batch_size]\n",
    "\n",
    "        step_inputs       = _embedding(self.x)\n",
    "        step_inputs       = _sequence_dropout(step_inputs, self.keep_prob)\n",
    "        step_enc_outputs  = sequence_encoding_n2n(step_inputs, seq_length, hps.enc_dim)\n",
    "        step_outputs      = _to_class_n2n(step_enc_outputs, hps.num_target_class)\n",
    "\n",
    "        self.loss = _loss(step_outputs, self.y, self.w)\n",
    "\n",
    "        # step_preds and step_out_probs\n",
    "        step_out_probs = []\n",
    "        step_out_preds = []\n",
    "        for _output in step_outputs:\n",
    "            _out_probs  = tf.nn.softmax(_output)\n",
    "            _out_pred   = tf.argmax(_out_probs, 1)\n",
    "\n",
    "            step_out_probs.append(_out_probs)\n",
    "            step_out_preds.append(_out_pred)\n",
    "\n",
    "        # stack for interface\n",
    "        self.step_out_probs = tf.stack(step_out_probs, axis=1, name=\"step_out_probs\")\n",
    "        self.step_out_preds = tf.stack(step_out_preds, axis=1, name=\"step_out_preds\")\n",
    "\n",
    "        self.global_step = tf.get_variable(\"global_step\", [], tf.int32, initializer=tf.zeros_initializer, trainable=False)\n",
    "\n",
    "        if mode == \"train\":\n",
    "            optimizer       = tf.train.AdamOptimizer(hps.learning_rate)\n",
    "            self.train_op   = optimizer.minimize(self.loss, global_step=self.global_step)\n",
    "        else:\n",
    "            self.train_op = tf.no_op()\n",
    "\n",
    "        for v in tf.trainable_variables(): print(v.name)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_hparams():\n",
    "        return HParams(\n",
    "            learning_rate     = 0.01,\n",
    "            keep_prob         = 0.5,\n",
    "        )\n",
    "\n",
    "\n",
    "def train(train_id_data, num_vocabs, num_taget_class):\n",
    "    #\n",
    "    # train sentiment analysis using given train_id_data\n",
    "    #\n",
    "    max_epoch = 600\n",
    "    model_dir = \"./trained_models\"\n",
    "    hps = NER.get_default_hparams()\n",
    "    hps.update(\n",
    "                    batch_size= 50,\n",
    "                    num_steps = 85,\n",
    "                    emb_size  = 50,\n",
    "                    enc_dim   = 50,\n",
    "                    vocab_size=num_vocabs,\n",
    "                    num_target_class=num_taget_class\n",
    "               )\n",
    "\n",
    "    with tf.variable_scope(\"model\"):\n",
    "        model = NER(hps, \"train\")\n",
    "\n",
    "    sv = tf.train.Supervisor(is_chief=True,\n",
    "                             logdir=model_dir,\n",
    "                             summary_op=None,  \n",
    "                             global_step=model.global_step)\n",
    "\n",
    "    # tf assign compatible operators for gpu and cpu \n",
    "    tf_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "\n",
    "    with sv.managed_session(config=tf_config) as sess:\n",
    "        local_step       = 0\n",
    "        prev_global_step = sess.run(model.global_step)\n",
    "\n",
    "        train_data_set = NERDataset(train_id_data, hps.batch_size, hps.num_steps)\n",
    "        losses = []\n",
    "        while not sv.should_stop():\n",
    "            fetches = [model.global_step, model.loss, model.train_op]\n",
    "            a_batch_data = next( train_data_set.iterator )\n",
    "            y, x, w = a_batch_data\n",
    "            fetched = sess.run(fetches, {\n",
    "                                            model.x: x, \n",
    "                                            model.y: y, \n",
    "                                            model.w: w,\n",
    "\n",
    "                                            model.keep_prob: hps.keep_prob,\n",
    "                                        }\n",
    "                              )\n",
    "\n",
    "            local_step += 1\n",
    "\n",
    "            _global_step = fetched[0]\n",
    "            _loss        = fetched[1]\n",
    "            losses.append( _loss )\n",
    "            if local_step < 10 or local_step % 10 == 0:\n",
    "                epoch = train_data_set.get_epoch_num()\n",
    "                print(\"Epoch = {:3d} Step = {:7d} loss = {:5.3f}\".format(epoch, _global_step, np.mean(losses)) )\n",
    "                _loss = []                \n",
    "                if epoch >= max_epoch : break \n",
    "\n",
    "        print(\"Training is done.\")\n",
    "    sv.stop()\n",
    "\n",
    "    # model.out_pred, model.out_probs\n",
    "    freeze_graph(model_dir, \"model/step_out_preds,model/step_out_probs\", \"frozen_graph.tf.pb\") ## freeze graph with params to probobuf format\n",
    "    \n",
    "from tensorflow.core.framework import graph_pb2\n",
    "def predict(token_vocab, target_vocab, sent):\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # force to use cpu only (prediction)\n",
    "    model_dir = \"./trained_models\"\n",
    "\n",
    "    # prepare sentence converting\n",
    "    # to make raw sentence to id data easily\n",
    "    pred_data     = N2NTextData(sent, mode='sentence')\n",
    "    pred_id_data  = N2NConverter.convert(pred_data, target_vocab, token_vocab)\n",
    "    pred_data_set = NERDataset(pred_id_data, 1, 85)\n",
    "    #\n",
    "    a_batch_data = next(pred_data_set.predict_iterator) # a result\n",
    "    b_nes_id, b_token_ids, b_weight = a_batch_data\n",
    "\n",
    "    # Restore graph\n",
    "    # note that frozen_graph.tf.pb contains graph definition with parameter values in binary format\n",
    "    _graph_fn =  os.path.join(model_dir, 'frozen_graph.tf.pb')\n",
    "    with tf.gfile.GFile(_graph_fn, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        # to check load graph\n",
    "        #for n in tf.get_default_graph().as_graph_def().node: print(n.name)\n",
    "\n",
    "        # make interface for input\n",
    "        pl_token     = graph.get_tensor_by_name('import/model/pl_tokens:0')\n",
    "        pl_weight    = graph.get_tensor_by_name('import/model/pl_weight:0')\n",
    "        pl_keep_prob = graph.get_tensor_by_name('import/model/pl_keep_prob:0')\n",
    "\n",
    "        # make interface for output\n",
    "        step_out_preds = graph.get_tensor_by_name('import/model/step_out_preds:0')\n",
    "        step_out_probs = graph.get_tensor_by_name('import/model/step_out_probs:0')\n",
    "        \n",
    "\n",
    "        # predict sentence \n",
    "        b_best_step_pred_indexs, b_step_pred_probs = sess.run([step_out_preds, step_out_probs], \n",
    "                                                              feed_dict={\n",
    "                                                                            pl_token  : b_token_ids,\n",
    "                                                                            pl_weight : b_weight,\n",
    "                                                                            pl_keep_prob : 1.0,\n",
    "                                                                        }\n",
    "                                                             )\n",
    "        best_step_pred_indexs = b_best_step_pred_indexs[0]\n",
    "        step_pred_probs = b_step_pred_probs[0]\n",
    "\n",
    "        step_best_targets = []\n",
    "        step_best_target_probs = []\n",
    "        for time_step, best_pred_index in enumerate(best_step_pred_indexs):\n",
    "            _target_class = target_vocab.get_symbol(best_pred_index)\n",
    "            step_best_targets.append( _target_class )\n",
    "            _prob = step_pred_probs[time_step][best_pred_index]\n",
    "            step_best_target_probs.append( _prob ) \n",
    "\n",
    "        for idx, char in enumerate(list(sent)):\n",
    "            print('{}\\t{}\\t{}'.format(char, step_best_targets[idx], step_best_target_probs[idx]) ) \n",
    "        #return list(sent)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_id_data, token_vocab, target_vocab = load_data()\n",
    "    num_vocabs       = token_vocab.get_num_tokens()\n",
    "    num_target_class = target_vocab.get_num_targets()\n",
    "\n",
    "    train_data_set = NERDataset(train_id_data, 5, 85)\n",
    "    train(train_id_data, num_vocabs, num_target_class)\n",
    "    \n",
    "    #predict(token_vocab, target_vocab, '아프가니스탄의 장래를 더욱 불투명하게 하는 것은 강경파 헤즈비 이슬라미와 우즈베크 민병대의 대립이다.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가\tO\t0.07877976447343826\n",
      "족\tB-PU\t0.07829836010932922\n",
      "이\tB-LC\t0.07853621244430542\n",
      "랑\tB-LC\t0.07850779592990875\n",
      " \tB-DT\t0.07845506072044373\n",
      "겨\tO\t0.07809155434370041\n",
      "울\tB-WT\t0.0790550634264946\n",
      "에\tB-WT\t0.078522689640522\n",
      " \tB-LC\t0.07874360680580139\n",
      "3\tB-AC\t0.07953814417123795\n",
      "박\tB-AC\t0.07909800112247467\n",
      "4\tB-DT\t0.07913843542337418\n",
      "일\tB-LC\t0.07922055572271347\n",
      " \tB-LC\t0.07910623401403427\n",
      "여\tI-PU\t0.07829412817955017\n",
      "행\tI-AC\t0.07860518246889114\n"
     ]
    }
   ],
   "source": [
    "predict(token_vocab, target_vocab, '가족이랑 겨울에 3박4일 여행')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
