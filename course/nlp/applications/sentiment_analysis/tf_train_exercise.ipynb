{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version :  1.9.0\n"
     ]
    }
   ],
   "source": [
    "import sys, os, inspect\n",
    "\n",
    "# add common to path\n",
    "from pathlib import Path\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "common_path = str(Path(currentdir).parent.parent)\n",
    "sys.path.append( common_path )\n",
    "\n",
    "from common.nlp.vocab import Vocab\n",
    "from common.nlp.data_loader import N21TextData\n",
    "from common.nlp.converter import N21Converter\n",
    "\n",
    "from dataset import SentimentDataset\n",
    "from dataset import load_data\n",
    "from common.ml.hparams import HParams\n",
    "\n",
    "import numpy as np\n",
    "import copy \n",
    "import time \n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn\n",
    "from tensorflow.contrib.layers.python.layers import linear\n",
    "\n",
    "from common.ml.tf.deploy import freeze_graph\n",
    "\n",
    "print( \"Tensorflow Version : \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'C:\\\\Users\\\\juni\\\\Anaconda3\\\\python36.zip',\n",
       " 'C:\\\\Users\\\\juni\\\\Anaconda3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\juni\\\\Anaconda3\\\\lib',\n",
       " 'C:\\\\Users\\\\juni\\\\Anaconda3',\n",
       " 'C:\\\\Users\\\\juni\\\\AppData\\\\Roaming\\\\Python\\\\Python36\\\\site-packages',\n",
       " 'C:\\\\Users\\\\juni\\\\Anaconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\juni\\\\Anaconda3\\\\lib\\\\site-packages\\\\Babel-2.5.0-py3.6.egg',\n",
       " 'C:\\\\Users\\\\juni\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\juni\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\juni\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\juni\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\juni\\\\.ipython',\n",
       " 'C:\\\\Users\\\\juni\\\\pythonNlp\\\\course\\\\nlp']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysis():\n",
    "    def __init__(self, hps, mode=\"train\"):\n",
    "        self.hps = hps\n",
    "        self.x = tf.placeholder(tf.int32, [None, hps.num_steps], name=\"pl_tokens\")#None: batch_size를 모르기 때문에 알아서 하도록 함\n",
    "        self.y = tf.placeholder(tf.int32, [None], name=\"pl_target\")#placeholder: 다른 텐서를 할당하기 위해사용, 이름도 써주는게 좋음\n",
    "        self.w = tf.placeholder(tf.float32, [None, hps.num_steps], name=\"pl_weight\")\n",
    "        self.keep_prob = tf.placeholder(tf.float32, [], name=\"pl_keep_prob\")\n",
    "\n",
    "        ### 4 blocks ###\n",
    "        # 1) embedding\n",
    "        # 2) dropout on input embedding\n",
    "        # 3) sentence encoding using rnn\n",
    "        # 4) encoding to output classes\n",
    "        # 5) loss calcaulation\n",
    "\n",
    "        def _embedding(x):\n",
    "            # character embedding \n",
    "            #print(\"-\"*100)\n",
    "            #print(\"Implement function '{}'\".format(_embedding.__name__))\n",
    "            #print(\"Keywords\")\n",
    "            #print(\"\\t - tf.initializers.variance_scaling\")\n",
    "            #print(\"\\t - tf.get_variable\")\n",
    "            #print(\"\\t - tf.nn.embedding_lookup\")\n",
    "            #print(\"\\t - tf.unstack\")\n",
    "\n",
    "            #print('Input : Tensor(\"model/pl_tokens:0\", shape=(?, 128), dtype=int32)')\n",
    "\n",
    "            \n",
    "            #print(\"Return: a list of <tf.Tensor shape=(?, 50) dtype=float32>\")\n",
    "            #print(\"        len(a_list) = 128\")\n",
    "            shape = [hps.vocab_size,hps.emb_size]\n",
    "            initializer = tf.initializers.variance_scaling(distribution=\"uniform\",dtype=tf.float32)#가중치 벡터의 shape에 맞게 조정\n",
    "            emb_mat = tf.get_variable('emb',shape,initializer=initializer,dtype=tf.float32)#입력한 파라미터에 맞는 데이터를 생성하거나 가져옴\n",
    "            input_emb = tf.nn.embedding_lookup(emb_mat,x)#embedding tensor리스트에서 id를 검색함\n",
    "            \n",
    "            step_inputs = tf.unstack(input_emb,axis=1) # split input_emb -> num_steps, tf.unstack: 랭크를 1줄임\n",
    "            return step_inputs\n",
    "\n",
    "        def _sequence_dropout(step_inputs, keep_prob):\n",
    "            # apply dropout to each input\n",
    "            # input : a list of input tensor which shape is [None, input_dim]\n",
    "            print(\"-\"*100)\n",
    "            with tf.name_scope('sequence_dropout') as scope:\n",
    "                #print(\"Implement step_outputs\")\n",
    "                #print(\"Keywords\")\n",
    "                #print(\"\\t - tf.nn.dropout\")\n",
    "                step_outputs=[]\n",
    "                for t,input in enumerate(step_inputs):\n",
    "                    step_outputs.append(tf.nn.dropout(input,keep_prob))\n",
    "\n",
    "\n",
    "\n",
    "            #print(\"Return: a list of <tf.Tensor shape=(?, 50) dtype=float32>\")\n",
    "            return step_outputs\n",
    "\n",
    "        def sequence_encoding_n21_rnn(step_inputs, cell_size, scope_name):\n",
    "            # rnn based N21 encoding (GRU)\n",
    "            #print(\"-\"*100)\n",
    "            #print(\"Implement function '{}'\".format(sequence_encoding_n21_rnn.__name__))\n",
    "            #print('Input : a list of <tf.Tensor shape=(?, 50), dtype=float32>')\n",
    "            #print(\"Keywords\")\n",
    "            #print(\"\\t - tf.contrib.rnn.GRUCell\")\n",
    "            #print(\"\\t - tf.contrib.rnn.static_rnn\")\n",
    "\n",
    "            #print(\"Return: a list of <tf.Tensor, shape=(?, 100)>\")\n",
    "            step_inputs=list(reversed(step_inputs))#뒤 쪽에 있는 패딩심볼의 악영향을 줄이기 위해 뒤에서 부터 인코딩\n",
    "            f_rnn_cell=tf.contrib.rnn.GRUCell(cell_size,reuse=None)\n",
    "            _inputs=tf.stack(step_inputs,axis=1)\n",
    "            step_outputs, final_state=tf.contrib.rnn.static_rnn(f_rnn_cell,\n",
    "                                                               step_inputs,\n",
    "                                                               dtype=tf.float32,\n",
    "                                                               scope=scope_name)#각 step별 output과 마지막 히든레이어를 결과로\n",
    "            out = step_outputs[-1]            \n",
    "            return out\n",
    "\n",
    "        def _to_class(input, num_class):\n",
    "            #print(\"-\"*100)\n",
    "            #print(\"Implement function '{}'\".format(_to_class.__name__))\n",
    "            #print('Input : tf.Tensor, shape=(?, 100), dtype=float32')\n",
    "            #print(\"Keywords\")\n",
    "            #print(\"\\t - tensorflow.contrib.layers.python.layers.linear\")\n",
    "\n",
    "            #print(\"Return: tf.Tensor, shape=(?, 4), dtype=float32\")\n",
    "            out = linear(input,num_class,scope=\"Rnn2Sentiment\") # should be implemented\n",
    "            return out\n",
    "\n",
    "        def _loss(out, ref):\n",
    "            # out : [batch_size, num_class] float - unscaled logits\n",
    "            # ref : [batch_size] integer\n",
    "            # calculate loss function using cross-entropy\n",
    "            #print(\"-\"*100)\n",
    "            #print('Input out: tf.Tensor, shape=(?, 4)')\n",
    "            #print('Input ref: tf.Tensor(\"model/pl_target:0\", shape=(?,), dtype=int32)')\n",
    "\n",
    "            #print(\"Keywords\")\n",
    "            #print(\"\\t - tf.nn.sparse_softmax_cross_entropy_with_logits\")\n",
    "            #print(\"\\t - tf.reduce_mean\")\n",
    "            \n",
    "            #print(\"Return: tf.Tensor, shape=(), dtype=float32\")\n",
    "            batch_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=out,labels=ref,name=\"sentiment_loss\")\n",
    "            loss =  tf.reduce_mean(batch_loss)# [batch_size,emb_dim=30]\n",
    "            return loss\n",
    "        \n",
    "        seq_length    = tf.reduce_sum(self.w, 1) # [batch_size]\n",
    "\n",
    "        step_inputs   = _embedding(self.x) # [batch_size,emb_dim=50]\n",
    "        step_inputs   = _sequence_dropout(step_inputs, self.keep_prob)\n",
    "        sent_encoding = sequence_encoding_n21_rnn(step_inputs, hps.enc_dim, scope_name=\"encoder\")#sentence encoding\n",
    "        out           = _to_class(sent_encoding, hps.num_target_class)\n",
    "        loss          = _loss(out, self.y) \n",
    "\n",
    "        if loss is None: \n",
    "            print(\"All functions should be implemented!\")\n",
    "            import sys; sys.exit()\n",
    "\n",
    "\n",
    "        out_probs     = tf.nn.softmax(out, name=\"out_probs\")\n",
    "        out_pred      = tf.argmax(out_probs, 1, name=\"out_pred\")\n",
    "\n",
    "        self.loss      = loss\n",
    "        self.out_probs = out_probs#[batch_size, num_class]\n",
    "        self.out_pred  = out_pred#[batch_size]\n",
    "\n",
    "        self.global_step = tf.get_variable(\"global_step\", [], tf.int32, initializer=tf.zeros_initializer, trainable=False)\n",
    "\n",
    "        if mode == \"train\":#backpropagation\n",
    "            optimizer       = tf.train.AdamOptimizer(hps.learning_rate)#자연어에서는 주로 adam사용\n",
    "            self.train_op   = optimizer.minimize(self.loss, global_step=self.global_step)\n",
    "        else:\n",
    "            self.train_op = tf.no_op()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_hparams():\n",
    "        return HParams(\n",
    "            learning_rate     = 0.001,\n",
    "            keep_prob         = 0.5,#문제의 손상율\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_id_data, num_vocabs, num_taget_class):\n",
    "    #\n",
    "    # train sentiment analysis using given train_id_data\n",
    "    #\n",
    "    max_epoch = 3000\n",
    "    model_dir = \"./trained_models\"\n",
    "    hps = SentimentAnalysis.get_default_hparams()\n",
    "    hps.update(\n",
    "                    batch_size= 100,\n",
    "                    num_steps = 128,#몇 개의 char가 들어오나? 즉 input\n",
    "                    emb_size  = 50,#조금 작은 값임\n",
    "                    enc_dim   = 100,#마지막 시퀀스 인코더의 dimension\n",
    "                    vocab_size=num_vocabs,\n",
    "                    num_target_class=num_taget_class\n",
    "               )\n",
    "\n",
    "    with tf.variable_scope(\"model\"):#해당 스코프안에서 정의되는 변수는 해당범위에만 한정되어짐\n",
    "        model = SentimentAnalysis(hps, \"train\")\n",
    "\n",
    "    sv = tf.train.Supervisor(is_chief=True,#프로그래밍 패턴중 하나, sv안에 세션을 담으면 알아서 다 해준다고 함\n",
    "                             logdir=model_dir,\n",
    "                             summary_op=None,  \n",
    "                             global_step=model.global_step)\n",
    "\n",
    "    # tf assign compatible operators for gpu and cpu \n",
    "    tf_config = tf.ConfigProto(allow_soft_placement=True)#cpu, gpu가 문제없이 돌아갈 수 있도록 해주는 역할\n",
    "\n",
    "    with sv.managed_session(config=tf_config) as sess:\n",
    "        local_step       = 0\n",
    "        prev_global_step = sess.run(model.global_step)\n",
    "\n",
    "        train_data_set = SentimentDataset(train_id_data, hps.batch_size, hps.num_steps)\n",
    "        losses = []\n",
    "        while not sv.should_stop():#미니배치로 실행\n",
    "            fetches = [model.global_step, model.loss, model.train_op]\n",
    "            a_batch_data = next( train_data_set.iterator )\n",
    "            y, x, w = a_batch_data\n",
    "            fetched = sess.run(fetches, {\n",
    "                                            model.x: x, \n",
    "                                            model.y: y, \n",
    "                                            model.w: w,\n",
    "\n",
    "                                            model.keep_prob: hps.keep_prob,\n",
    "                                        }\n",
    "                              )\n",
    "\n",
    "            local_step += 1\n",
    "\n",
    "            _global_step = fetched[0]\n",
    "            _loss        = fetched[1]\n",
    "            losses.append( _loss )\n",
    "            if local_step < 10 or local_step % 10 == 0:\n",
    "                epoch = train_data_set.get_epoch_num()\n",
    "                print(\"Epoch = {:3d} Step = {:7d} loss = {:5.3f}\".format(epoch, _global_step, np.mean(losses)) )\n",
    "                _loss = []                \n",
    "                if epoch >= max_epoch : break \n",
    "\n",
    "        print(\"Training is done.\")\n",
    "    sv.stop()\n",
    "\n",
    "    # model.out_pred, model.out_probs\n",
    "    freeze_graph(model_dir, \"model/out_pred,model/out_probs\", \"frozen_graph.tf.pb\") ## freeze graph with params to probobuf format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.core.framework import graph_pb2\n",
    "def predict(token_vocab, target_vocab, sent):\n",
    "    #os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # force to use cpu only (prediction)\n",
    "    os.environ['CUDA_DEVICE_ORDER']=\"PCI_BUS_ID\"\n",
    "    os.environ['CUDA_VISIBLE_DEVICES']='0'# force to use gpu only (prediction)\n",
    "    model_dir = \"./trained_models\"\n",
    "\n",
    "    # prepare sentence converting\n",
    "    # to make raw sentence to id data easily\n",
    "    in_sent = '{}\\t{}'.format('___DUMMY_CLASS___', sent)\n",
    "    pred_data     = N21TextData(in_sent, mode='sentence')\n",
    "    pred_id_data  = N21Converter.convert(pred_data, target_vocab, token_vocab)\n",
    "    pred_data_set = SentimentDataset(pred_id_data, 1, 128)\n",
    "\n",
    "    #\n",
    "    a_batch_data = next(pred_data_set.predict_iterator) # a result\n",
    "    b_sentiment_id, b_token_ids, b_weight = a_batch_data\n",
    "\n",
    "    # Restore graph\n",
    "    # note that frozen_graph.tf.pb contains graph definition with parameter values in binary format\n",
    "    _graph_fn =  os.path.join(model_dir, 'frozen_graph.tf.pb')\n",
    "    with tf.gfile.GFile(_graph_fn, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        # to check load graph\n",
    "        #for n in tf.get_default_graph().as_graph_def().node: print(n.name)\n",
    "\n",
    "        # make interface for input\n",
    "        pl_token     = graph.get_tensor_by_name('import/model/pl_tokens:0')\n",
    "        pl_keep_prob = graph.get_tensor_by_name('import/model/pl_keep_prob:0')\n",
    "\n",
    "        # make interface for output\n",
    "        out_pred  = graph.get_tensor_by_name('import/model/out_pred:0')\n",
    "        out_probs = graph.get_tensor_by_name('import/model/out_probs:0')\n",
    "        \n",
    "\n",
    "        # predict sentence \n",
    "        b_best_pred_index, b_pred_probs = sess.run([out_pred, out_probs], feed_dict={\n",
    "                                                                                        pl_token : b_token_ids,\n",
    "                                                                                        pl_keep_prob : 1.0,\n",
    "                                                                                    }\n",
    "                                          )\n",
    "\n",
    "        best_pred_index = b_best_pred_index[0]\n",
    "        pred_probs = b_pred_probs[0]\n",
    "        #결과 출력 루틴\n",
    "        best_target_class = target_vocab.get_symbol(best_pred_index)\n",
    "        print( pred_probs[best_pred_index] )\n",
    "        best_prob  = int( pred_probs[best_pred_index] )\n",
    "        print(best_target_class, best_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "WARNING:tensorflow:From <ipython-input-3-1c8f1a90716b>:23: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "INFO:tensorflow:Restoring parameters from ./trained_models\\model.ckpt-26873\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Saving checkpoint to path ./trained_models\\model.ckpt\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:model/global_step/sec: 0\n",
      "Epoch =   1 Step =   26874 loss = 0.000\n",
      "Epoch =   1 Step =   26875 loss = 0.004\n",
      "Epoch =   1 Step =   26876 loss = 0.003\n",
      "Epoch =   1 Step =   26877 loss = 0.002\n",
      "Epoch =   2 Step =   26878 loss = 0.002\n",
      "Epoch =   2 Step =   26879 loss = 0.002\n",
      "Epoch =   2 Step =   26880 loss = 0.001\n",
      "Epoch =   2 Step =   26881 loss = 0.001\n",
      "Epoch =   2 Step =   26882 loss = 0.001\n",
      "Epoch =   3 Step =   26883 loss = 0.001\n",
      "Epoch =   5 Step =   26893 loss = 0.001\n",
      "Epoch =   7 Step =   26903 loss = 0.001\n",
      "Epoch =   9 Step =   26913 loss = 0.001\n",
      "Epoch =  11 Step =   26923 loss = 0.001\n",
      "Epoch =  13 Step =   26933 loss = 0.001\n",
      "Epoch =  15 Step =   26943 loss = 0.001\n",
      "Epoch =  17 Step =   26953 loss = 0.003\n",
      "Epoch =  19 Step =   26963 loss = 0.005\n",
      "Epoch =  21 Step =   26973 loss = 0.005\n",
      "Epoch =  23 Step =   26983 loss = 0.005\n",
      "Epoch =  25 Step =   26993 loss = 0.008\n",
      "Epoch =  27 Step =   27003 loss = 0.008\n",
      "Epoch =  29 Step =   27013 loss = 0.008\n",
      "Epoch =  31 Step =   27023 loss = 0.007\n",
      "Epoch =  33 Step =   27033 loss = 0.007\n",
      "Epoch =  35 Step =   27043 loss = 0.007\n",
      "Epoch =  37 Step =   27053 loss = 0.007\n",
      "Epoch =  39 Step =   27063 loss = 0.006\n",
      "Epoch =  41 Step =   27073 loss = 0.006\n",
      "Epoch =  43 Step =   27083 loss = 0.006\n",
      "Epoch =  45 Step =   27093 loss = 0.006\n",
      "Epoch =  47 Step =   27103 loss = 0.006\n",
      "Epoch =  49 Step =   27113 loss = 0.005\n",
      "Epoch =  51 Step =   27123 loss = 0.005\n",
      "Epoch =  53 Step =   27133 loss = 0.005\n",
      "Epoch =  55 Step =   27143 loss = 0.005\n",
      "Epoch =  57 Step =   27153 loss = 0.005\n",
      "Epoch =  59 Step =   27163 loss = 0.005\n",
      "Epoch =  61 Step =   27173 loss = 0.005\n",
      "Epoch =  63 Step =   27183 loss = 0.005\n",
      "Epoch =  65 Step =   27193 loss = 0.005\n",
      "Epoch =  67 Step =   27203 loss = 0.005\n",
      "Epoch =  69 Step =   27213 loss = 0.005\n",
      "Epoch =  71 Step =   27223 loss = 0.005\n",
      "Epoch =  73 Step =   27233 loss = 0.005\n",
      "Epoch =  75 Step =   27243 loss = 0.005\n",
      "Epoch =  77 Step =   27253 loss = 0.005\n",
      "Epoch =  79 Step =   27263 loss = 0.005\n",
      "Epoch =  81 Step =   27273 loss = 0.005\n",
      "Epoch =  83 Step =   27283 loss = 0.005\n",
      "Epoch =  85 Step =   27293 loss = 0.005\n",
      "Epoch =  87 Step =   27303 loss = 0.004\n",
      "Epoch =  89 Step =   27313 loss = 0.004\n",
      "Epoch =  91 Step =   27323 loss = 0.004\n",
      "Epoch =  93 Step =   27333 loss = 0.004\n",
      "Epoch =  95 Step =   27343 loss = 0.004\n",
      "Epoch =  97 Step =   27353 loss = 0.004\n",
      "Epoch =  99 Step =   27363 loss = 0.004\n",
      "Epoch = 101 Step =   27373 loss = 0.004\n",
      "Epoch = 103 Step =   27383 loss = 0.004\n",
      "Epoch = 105 Step =   27393 loss = 0.004\n",
      "Epoch = 107 Step =   27403 loss = 0.004\n",
      "Epoch = 109 Step =   27413 loss = 0.004\n",
      "Epoch = 111 Step =   27423 loss = 0.004\n",
      "Epoch = 113 Step =   27433 loss = 0.004\n",
      "Epoch = 115 Step =   27443 loss = 0.004\n",
      "Epoch = 117 Step =   27453 loss = 0.004\n",
      "Epoch = 119 Step =   27463 loss = 0.004\n",
      "Epoch = 121 Step =   27473 loss = 0.004\n",
      "Epoch = 123 Step =   27483 loss = 0.004\n",
      "Epoch = 125 Step =   27493 loss = 0.004\n",
      "Epoch = 127 Step =   27503 loss = 0.004\n",
      "Epoch = 129 Step =   27513 loss = 0.003\n",
      "Epoch = 131 Step =   27523 loss = 0.003\n",
      "Epoch = 133 Step =   27533 loss = 0.003\n",
      "Epoch = 135 Step =   27543 loss = 0.003\n",
      "Epoch = 137 Step =   27553 loss = 0.003\n",
      "Epoch = 139 Step =   27563 loss = 0.003\n",
      "Epoch = 141 Step =   27573 loss = 0.003\n",
      "Epoch = 143 Step =   27583 loss = 0.003\n",
      "Epoch = 145 Step =   27593 loss = 0.003\n",
      "Epoch = 147 Step =   27603 loss = 0.003\n",
      "Epoch = 149 Step =   27613 loss = 0.003\n",
      "Epoch = 151 Step =   27623 loss = 0.003\n",
      "Epoch = 153 Step =   27633 loss = 0.003\n",
      "Epoch = 155 Step =   27643 loss = 0.003\n",
      "Epoch = 157 Step =   27653 loss = 0.003\n",
      "Epoch = 159 Step =   27663 loss = 0.003\n",
      "Epoch = 161 Step =   27673 loss = 0.003\n",
      "Epoch = 163 Step =   27683 loss = 0.003\n",
      "Epoch = 165 Step =   27693 loss = 0.003\n",
      "Epoch = 167 Step =   27703 loss = 0.003\n",
      "INFO:tensorflow:model/global_step/sec: 6.97475\n",
      "Epoch = 169 Step =   27713 loss = 0.003\n",
      "Epoch = 171 Step =   27723 loss = 0.003\n",
      "Epoch = 173 Step =   27733 loss = 0.003\n",
      "Epoch = 175 Step =   27743 loss = 0.003\n",
      "Epoch = 177 Step =   27753 loss = 0.003\n",
      "Epoch = 179 Step =   27763 loss = 0.003\n",
      "Epoch = 181 Step =   27773 loss = 0.003\n",
      "Epoch = 183 Step =   27783 loss = 0.003\n",
      "Epoch = 185 Step =   27793 loss = 0.003\n",
      "Epoch = 187 Step =   27803 loss = 0.003\n",
      "Epoch = 189 Step =   27813 loss = 0.003\n",
      "Epoch = 191 Step =   27823 loss = 0.003\n",
      "Epoch = 193 Step =   27833 loss = 0.003\n",
      "Epoch = 195 Step =   27843 loss = 0.003\n",
      "Epoch = 197 Step =   27853 loss = 0.003\n",
      "Epoch = 199 Step =   27863 loss = 0.003\n",
      "Epoch = 201 Step =   27873 loss = 0.003\n",
      "Epoch = 203 Step =   27883 loss = 0.003\n",
      "Epoch = 205 Step =   27893 loss = 0.003\n",
      "Epoch = 207 Step =   27903 loss = 0.003\n",
      "Epoch = 209 Step =   27913 loss = 0.003\n",
      "Epoch = 211 Step =   27923 loss = 0.003\n",
      "Epoch = 213 Step =   27933 loss = 0.003\n",
      "Epoch = 215 Step =   27943 loss = 0.003\n",
      "Epoch = 217 Step =   27953 loss = 0.003\n",
      "Epoch = 219 Step =   27963 loss = 0.003\n",
      "Epoch = 221 Step =   27973 loss = 0.003\n",
      "Epoch = 223 Step =   27983 loss = 0.003\n",
      "Epoch = 225 Step =   27993 loss = 0.003\n",
      "Epoch = 227 Step =   28003 loss = 0.003\n",
      "Epoch = 229 Step =   28013 loss = 0.003\n",
      "Epoch = 231 Step =   28023 loss = 0.003\n",
      "Epoch = 233 Step =   28033 loss = 0.003\n",
      "Epoch = 235 Step =   28043 loss = 0.003\n",
      "Epoch = 237 Step =   28053 loss = 0.003\n",
      "Epoch = 239 Step =   28063 loss = 0.003\n",
      "Epoch = 241 Step =   28073 loss = 0.003\n",
      "Epoch = 243 Step =   28083 loss = 0.003\n",
      "Epoch = 245 Step =   28093 loss = 0.003\n",
      "Epoch = 247 Step =   28103 loss = 0.003\n",
      "Epoch = 249 Step =   28113 loss = 0.002\n",
      "Epoch = 251 Step =   28123 loss = 0.002\n",
      "Epoch = 253 Step =   28133 loss = 0.002\n",
      "Epoch = 255 Step =   28143 loss = 0.002\n",
      "Epoch = 257 Step =   28153 loss = 0.002\n",
      "Epoch = 259 Step =   28163 loss = 0.002\n",
      "Epoch = 261 Step =   28173 loss = 0.002\n",
      "Epoch = 263 Step =   28183 loss = 0.002\n",
      "Epoch = 265 Step =   28193 loss = 0.002\n",
      "Epoch = 267 Step =   28203 loss = 0.002\n",
      "Epoch = 269 Step =   28213 loss = 0.002\n",
      "Epoch = 271 Step =   28223 loss = 0.002\n",
      "Epoch = 273 Step =   28233 loss = 0.002\n",
      "Epoch = 275 Step =   28243 loss = 0.002\n",
      "Epoch = 277 Step =   28253 loss = 0.002\n",
      "Epoch = 279 Step =   28263 loss = 0.002\n",
      "Epoch = 281 Step =   28273 loss = 0.002\n",
      "Epoch = 283 Step =   28283 loss = 0.002\n",
      "Epoch = 285 Step =   28293 loss = 0.002\n",
      "Epoch = 287 Step =   28303 loss = 0.002\n",
      "Epoch = 289 Step =   28313 loss = 0.002\n",
      "Epoch = 291 Step =   28323 loss = 0.002\n",
      "Epoch = 293 Step =   28333 loss = 0.002\n",
      "Epoch = 295 Step =   28343 loss = 0.002\n",
      "Epoch = 297 Step =   28353 loss = 0.002\n",
      "Epoch = 299 Step =   28363 loss = 0.002\n",
      "Epoch = 301 Step =   28373 loss = 0.002\n",
      "Epoch = 303 Step =   28383 loss = 0.002\n",
      "Epoch = 305 Step =   28393 loss = 0.002\n",
      "Epoch = 307 Step =   28403 loss = 0.002\n",
      "Epoch = 309 Step =   28413 loss = 0.002\n",
      "Epoch = 311 Step =   28423 loss = 0.002\n",
      "Epoch = 313 Step =   28433 loss = 0.002\n",
      "Epoch = 315 Step =   28443 loss = 0.002\n",
      "Epoch = 317 Step =   28453 loss = 0.002\n",
      "Epoch = 319 Step =   28463 loss = 0.002\n",
      "Epoch = 321 Step =   28473 loss = 0.002\n",
      "Epoch = 323 Step =   28483 loss = 0.002\n",
      "Epoch = 325 Step =   28493 loss = 0.002\n",
      "Epoch = 327 Step =   28503 loss = 0.002\n",
      "Epoch = 329 Step =   28513 loss = 0.002\n",
      "Epoch = 331 Step =   28523 loss = 0.002\n",
      "Epoch = 333 Step =   28533 loss = 0.002\n",
      "Epoch = 335 Step =   28543 loss = 0.002\n",
      "Epoch = 337 Step =   28553 loss = 0.002\n",
      "Epoch = 339 Step =   28563 loss = 0.002\n",
      "Epoch = 341 Step =   28573 loss = 0.002\n",
      "Epoch = 343 Step =   28583 loss = 0.002\n",
      "Epoch = 345 Step =   28593 loss = 0.002\n",
      "Epoch = 347 Step =   28603 loss = 0.002\n",
      "Epoch = 349 Step =   28613 loss = 0.002\n",
      "INFO:tensorflow:model/global_step/sec: 7.54211\n",
      "Epoch = 351 Step =   28623 loss = 0.002\n",
      "Epoch = 353 Step =   28633 loss = 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 355 Step =   28643 loss = 0.002\n",
      "Epoch = 357 Step =   28653 loss = 0.002\n",
      "Epoch = 359 Step =   28663 loss = 0.002\n",
      "Epoch = 361 Step =   28673 loss = 0.002\n",
      "Epoch = 363 Step =   28683 loss = 0.002\n",
      "Epoch = 365 Step =   28693 loss = 0.002\n",
      "Epoch = 367 Step =   28703 loss = 0.002\n",
      "Epoch = 369 Step =   28713 loss = 0.002\n",
      "Epoch = 371 Step =   28723 loss = 0.002\n",
      "Epoch = 373 Step =   28733 loss = 0.002\n",
      "Epoch = 375 Step =   28743 loss = 0.002\n",
      "Epoch = 377 Step =   28753 loss = 0.002\n",
      "Epoch = 379 Step =   28763 loss = 0.002\n",
      "Epoch = 381 Step =   28773 loss = 0.002\n",
      "Epoch = 383 Step =   28783 loss = 0.002\n",
      "Epoch = 385 Step =   28793 loss = 0.002\n",
      "Epoch = 387 Step =   28803 loss = 0.002\n",
      "Epoch = 389 Step =   28813 loss = 0.002\n",
      "Epoch = 391 Step =   28823 loss = 0.002\n",
      "Epoch = 393 Step =   28833 loss = 0.002\n",
      "Epoch = 395 Step =   28843 loss = 0.002\n",
      "Epoch = 397 Step =   28853 loss = 0.002\n",
      "Epoch = 399 Step =   28863 loss = 0.002\n",
      "Epoch = 401 Step =   28873 loss = 0.002\n",
      "Epoch = 403 Step =   28883 loss = 0.002\n",
      "Epoch = 405 Step =   28893 loss = 0.002\n",
      "Epoch = 407 Step =   28903 loss = 0.002\n",
      "Epoch = 409 Step =   28913 loss = 0.002\n",
      "Epoch = 411 Step =   28923 loss = 0.002\n",
      "Epoch = 413 Step =   28933 loss = 0.002\n",
      "Epoch = 415 Step =   28943 loss = 0.002\n",
      "Epoch = 417 Step =   28953 loss = 0.002\n",
      "Epoch = 419 Step =   28963 loss = 0.002\n",
      "Epoch = 421 Step =   28973 loss = 0.002\n",
      "Epoch = 423 Step =   28983 loss = 0.002\n",
      "Epoch = 425 Step =   28993 loss = 0.002\n",
      "Epoch = 427 Step =   29003 loss = 0.002\n",
      "Epoch = 429 Step =   29013 loss = 0.002\n",
      "Epoch = 431 Step =   29023 loss = 0.002\n",
      "Epoch = 433 Step =   29033 loss = 0.002\n",
      "Epoch = 435 Step =   29043 loss = 0.002\n",
      "Epoch = 437 Step =   29053 loss = 0.002\n",
      "Epoch = 439 Step =   29063 loss = 0.002\n",
      "Epoch = 441 Step =   29073 loss = 0.002\n",
      "Epoch = 443 Step =   29083 loss = 0.002\n",
      "Epoch = 445 Step =   29093 loss = 0.002\n",
      "Epoch = 447 Step =   29103 loss = 0.002\n",
      "Epoch = 449 Step =   29113 loss = 0.002\n",
      "Epoch = 451 Step =   29123 loss = 0.002\n",
      "Epoch = 453 Step =   29133 loss = 0.002\n",
      "Epoch = 455 Step =   29143 loss = 0.002\n",
      "Epoch = 457 Step =   29153 loss = 0.002\n",
      "Epoch = 459 Step =   29163 loss = 0.002\n",
      "Epoch = 461 Step =   29173 loss = 0.002\n",
      "Epoch = 463 Step =   29183 loss = 0.002\n",
      "Epoch = 465 Step =   29193 loss = 0.002\n",
      "Epoch = 467 Step =   29203 loss = 0.002\n",
      "Epoch = 469 Step =   29213 loss = 0.002\n",
      "Epoch = 471 Step =   29223 loss = 0.002\n",
      "Epoch = 473 Step =   29233 loss = 0.002\n",
      "Epoch = 475 Step =   29243 loss = 0.002\n",
      "Epoch = 477 Step =   29253 loss = 0.002\n",
      "Epoch = 479 Step =   29263 loss = 0.002\n",
      "Epoch = 481 Step =   29273 loss = 0.002\n",
      "Epoch = 483 Step =   29283 loss = 0.002\n",
      "Epoch = 485 Step =   29293 loss = 0.002\n",
      "Epoch = 487 Step =   29303 loss = 0.002\n",
      "Epoch = 489 Step =   29313 loss = 0.002\n",
      "Epoch = 491 Step =   29323 loss = 0.002\n",
      "Epoch = 493 Step =   29333 loss = 0.002\n",
      "Epoch = 495 Step =   29343 loss = 0.002\n",
      "Epoch = 497 Step =   29353 loss = 0.002\n",
      "Epoch = 499 Step =   29363 loss = 0.002\n",
      "Epoch = 502 Step =   29373 loss = 0.002\n",
      "Epoch = 504 Step =   29383 loss = 0.002\n",
      "Epoch = 506 Step =   29393 loss = 0.002\n",
      "Epoch = 508 Step =   29403 loss = 0.002\n",
      "Epoch = 510 Step =   29413 loss = 0.002\n",
      "Epoch = 512 Step =   29423 loss = 0.002\n",
      "Epoch = 514 Step =   29433 loss = 0.002\n",
      "Epoch = 516 Step =   29443 loss = 0.002\n",
      "Epoch = 518 Step =   29453 loss = 0.002\n",
      "Epoch = 520 Step =   29463 loss = 0.002\n",
      "Epoch = 522 Step =   29473 loss = 0.002\n",
      "Epoch = 524 Step =   29483 loss = 0.002\n",
      "Epoch = 526 Step =   29493 loss = 0.002\n",
      "Epoch = 528 Step =   29503 loss = 0.002\n",
      "Epoch = 530 Step =   29513 loss = 0.002\n",
      "Epoch = 532 Step =   29523 loss = 0.002\n",
      "INFO:tensorflow:model/global_step/sec: 7.56657\n",
      "Epoch = 534 Step =   29533 loss = 0.002\n",
      "Epoch = 536 Step =   29543 loss = 0.002\n",
      "Epoch = 538 Step =   29553 loss = 0.002\n",
      "Epoch = 540 Step =   29563 loss = 0.002\n",
      "Epoch = 542 Step =   29573 loss = 0.002\n",
      "Epoch = 544 Step =   29583 loss = 0.002\n",
      "Epoch = 546 Step =   29593 loss = 0.002\n",
      "Epoch = 548 Step =   29603 loss = 0.002\n",
      "Epoch = 550 Step =   29613 loss = 0.002\n",
      "Epoch = 552 Step =   29623 loss = 0.002\n",
      "Epoch = 554 Step =   29633 loss = 0.002\n",
      "Epoch = 556 Step =   29643 loss = 0.002\n",
      "Epoch = 558 Step =   29653 loss = 0.002\n",
      "Epoch = 560 Step =   29663 loss = 0.002\n",
      "Epoch = 562 Step =   29673 loss = 0.002\n",
      "Epoch = 564 Step =   29683 loss = 0.002\n",
      "Epoch = 566 Step =   29693 loss = 0.002\n",
      "Epoch = 568 Step =   29703 loss = 0.002\n",
      "Epoch = 570 Step =   29713 loss = 0.002\n",
      "Epoch = 572 Step =   29723 loss = 0.002\n",
      "Epoch = 574 Step =   29733 loss = 0.002\n",
      "Epoch = 576 Step =   29743 loss = 0.002\n",
      "Epoch = 578 Step =   29753 loss = 0.002\n",
      "Epoch = 580 Step =   29763 loss = 0.002\n",
      "Epoch = 582 Step =   29773 loss = 0.002\n",
      "Epoch = 584 Step =   29783 loss = 0.002\n",
      "Epoch = 586 Step =   29793 loss = 0.002\n",
      "Epoch = 588 Step =   29803 loss = 0.002\n",
      "Epoch = 590 Step =   29813 loss = 0.002\n",
      "Epoch = 592 Step =   29823 loss = 0.002\n",
      "Epoch = 594 Step =   29833 loss = 0.002\n",
      "Epoch = 596 Step =   29843 loss = 0.002\n",
      "Epoch = 598 Step =   29853 loss = 0.002\n",
      "Epoch = 600 Step =   29863 loss = 0.002\n",
      "Epoch = 602 Step =   29873 loss = 0.002\n",
      "Epoch = 604 Step =   29883 loss = 0.002\n",
      "Epoch = 606 Step =   29893 loss = 0.002\n",
      "Epoch = 608 Step =   29903 loss = 0.002\n",
      "Epoch = 610 Step =   29913 loss = 0.002\n",
      "Epoch = 612 Step =   29923 loss = 0.002\n",
      "Epoch = 614 Step =   29933 loss = 0.002\n",
      "Epoch = 616 Step =   29943 loss = 0.002\n",
      "Epoch = 618 Step =   29953 loss = 0.002\n",
      "Epoch = 620 Step =   29963 loss = 0.002\n",
      "Epoch = 622 Step =   29973 loss = 0.002\n",
      "Epoch = 624 Step =   29983 loss = 0.002\n",
      "Epoch = 626 Step =   29993 loss = 0.002\n",
      "Epoch = 628 Step =   30003 loss = 0.002\n",
      "Epoch = 630 Step =   30013 loss = 0.002\n",
      "Epoch = 632 Step =   30023 loss = 0.002\n",
      "Epoch = 634 Step =   30033 loss = 0.002\n",
      "Epoch = 636 Step =   30043 loss = 0.002\n",
      "Epoch = 638 Step =   30053 loss = 0.002\n",
      "Epoch = 640 Step =   30063 loss = 0.002\n",
      "Epoch = 642 Step =   30073 loss = 0.002\n",
      "Epoch = 644 Step =   30083 loss = 0.002\n",
      "Epoch = 646 Step =   30093 loss = 0.002\n",
      "Epoch = 648 Step =   30103 loss = 0.002\n",
      "Epoch = 650 Step =   30113 loss = 0.002\n",
      "Epoch = 652 Step =   30123 loss = 0.002\n",
      "Epoch = 654 Step =   30133 loss = 0.002\n",
      "Epoch = 656 Step =   30143 loss = 0.002\n",
      "Epoch = 658 Step =   30153 loss = 0.002\n",
      "Epoch = 660 Step =   30163 loss = 0.002\n",
      "Epoch = 662 Step =   30173 loss = 0.002\n",
      "Epoch = 664 Step =   30183 loss = 0.002\n",
      "Epoch = 666 Step =   30193 loss = 0.002\n",
      "Epoch = 668 Step =   30203 loss = 0.002\n",
      "Epoch = 670 Step =   30213 loss = 0.002\n",
      "Epoch = 672 Step =   30223 loss = 0.002\n",
      "Epoch = 674 Step =   30233 loss = 0.002\n",
      "Epoch = 676 Step =   30243 loss = 0.002\n",
      "Epoch = 678 Step =   30253 loss = 0.002\n",
      "Epoch = 680 Step =   30263 loss = 0.002\n",
      "Epoch = 682 Step =   30273 loss = 0.002\n",
      "Epoch = 684 Step =   30283 loss = 0.002\n",
      "Epoch = 686 Step =   30293 loss = 0.002\n",
      "Epoch = 688 Step =   30303 loss = 0.002\n",
      "Epoch = 690 Step =   30313 loss = 0.002\n",
      "Epoch = 692 Step =   30323 loss = 0.002\n",
      "Epoch = 694 Step =   30333 loss = 0.002\n",
      "Epoch = 696 Step =   30343 loss = 0.002\n",
      "Epoch = 698 Step =   30353 loss = 0.002\n",
      "Epoch = 700 Step =   30363 loss = 0.002\n",
      "Epoch = 702 Step =   30373 loss = 0.002\n",
      "Epoch = 704 Step =   30383 loss = 0.002\n",
      "Epoch = 706 Step =   30393 loss = 0.002\n",
      "Epoch = 708 Step =   30403 loss = 0.002\n",
      "Epoch = 710 Step =   30413 loss = 0.002\n",
      "INFO:tensorflow:model/global_step/sec: 7.49137\n",
      "Epoch = 712 Step =   30423 loss = 0.002\n",
      "Epoch = 714 Step =   30433 loss = 0.002\n",
      "Epoch = 716 Step =   30443 loss = 0.002\n",
      "Epoch = 718 Step =   30453 loss = 0.002\n",
      "Epoch = 720 Step =   30463 loss = 0.002\n",
      "Epoch = 722 Step =   30473 loss = 0.002\n",
      "Epoch = 724 Step =   30483 loss = 0.002\n",
      "Epoch = 726 Step =   30493 loss = 0.002\n",
      "Epoch = 728 Step =   30503 loss = 0.002\n",
      "Epoch = 730 Step =   30513 loss = 0.002\n",
      "Epoch = 732 Step =   30523 loss = 0.002\n",
      "Epoch = 734 Step =   30533 loss = 0.002\n",
      "Epoch = 736 Step =   30543 loss = 0.002\n",
      "Epoch = 738 Step =   30553 loss = 0.002\n",
      "Epoch = 740 Step =   30563 loss = 0.002\n",
      "Epoch = 742 Step =   30573 loss = 0.002\n",
      "Epoch = 744 Step =   30583 loss = 0.002\n",
      "Epoch = 746 Step =   30593 loss = 0.002\n",
      "Epoch = 748 Step =   30603 loss = 0.002\n",
      "Epoch = 750 Step =   30613 loss = 0.002\n",
      "Epoch = 752 Step =   30623 loss = 0.002\n",
      "Epoch = 754 Step =   30633 loss = 0.002\n",
      "Epoch = 756 Step =   30643 loss = 0.002\n",
      "Epoch = 758 Step =   30653 loss = 0.002\n",
      "Epoch = 760 Step =   30663 loss = 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 762 Step =   30673 loss = 0.002\n",
      "Epoch = 764 Step =   30683 loss = 0.002\n",
      "Epoch = 766 Step =   30693 loss = 0.002\n",
      "Epoch = 768 Step =   30703 loss = 0.002\n",
      "Epoch = 770 Step =   30713 loss = 0.002\n",
      "Epoch = 772 Step =   30723 loss = 0.002\n",
      "Epoch = 774 Step =   30733 loss = 0.002\n",
      "Epoch = 776 Step =   30743 loss = 0.002\n",
      "Epoch = 778 Step =   30753 loss = 0.002\n",
      "Epoch = 780 Step =   30763 loss = 0.002\n",
      "Epoch = 782 Step =   30773 loss = 0.002\n",
      "Epoch = 784 Step =   30783 loss = 0.002\n",
      "Epoch = 786 Step =   30793 loss = 0.002\n",
      "Epoch = 788 Step =   30803 loss = 0.002\n",
      "Epoch = 790 Step =   30813 loss = 0.002\n",
      "Epoch = 792 Step =   30823 loss = 0.002\n",
      "Epoch = 794 Step =   30833 loss = 0.002\n",
      "Epoch = 796 Step =   30843 loss = 0.002\n",
      "Epoch = 798 Step =   30853 loss = 0.002\n",
      "Epoch = 800 Step =   30863 loss = 0.002\n",
      "Epoch = 802 Step =   30873 loss = 0.002\n",
      "Epoch = 804 Step =   30883 loss = 0.002\n",
      "Epoch = 806 Step =   30893 loss = 0.002\n",
      "Epoch = 808 Step =   30903 loss = 0.002\n",
      "Epoch = 810 Step =   30913 loss = 0.002\n",
      "Epoch = 812 Step =   30923 loss = 0.002\n",
      "Epoch = 814 Step =   30933 loss = 0.002\n",
      "Epoch = 816 Step =   30943 loss = 0.002\n",
      "Epoch = 818 Step =   30953 loss = 0.002\n",
      "Epoch = 820 Step =   30963 loss = 0.002\n",
      "Epoch = 822 Step =   30973 loss = 0.002\n",
      "Epoch = 824 Step =   30983 loss = 0.002\n",
      "Epoch = 826 Step =   30993 loss = 0.002\n",
      "Epoch = 828 Step =   31003 loss = 0.002\n",
      "Epoch = 830 Step =   31013 loss = 0.002\n",
      "Epoch = 832 Step =   31023 loss = 0.002\n",
      "Epoch = 834 Step =   31033 loss = 0.002\n",
      "Epoch = 836 Step =   31043 loss = 0.002\n",
      "Epoch = 838 Step =   31053 loss = 0.002\n",
      "Epoch = 840 Step =   31063 loss = 0.002\n",
      "Epoch = 842 Step =   31073 loss = 0.002\n",
      "Epoch = 844 Step =   31083 loss = 0.002\n",
      "Epoch = 846 Step =   31093 loss = 0.002\n",
      "Epoch = 848 Step =   31103 loss = 0.002\n",
      "Epoch = 850 Step =   31113 loss = 0.002\n",
      "Epoch = 852 Step =   31123 loss = 0.002\n",
      "Epoch = 854 Step =   31133 loss = 0.002\n",
      "Epoch = 856 Step =   31143 loss = 0.002\n",
      "Epoch = 858 Step =   31153 loss = 0.002\n",
      "Epoch = 860 Step =   31163 loss = 0.002\n",
      "Epoch = 862 Step =   31173 loss = 0.002\n",
      "Epoch = 864 Step =   31183 loss = 0.002\n",
      "Epoch = 866 Step =   31193 loss = 0.002\n",
      "Epoch = 868 Step =   31203 loss = 0.002\n",
      "Epoch = 870 Step =   31213 loss = 0.002\n",
      "Epoch = 872 Step =   31223 loss = 0.002\n",
      "Epoch = 874 Step =   31233 loss = 0.002\n",
      "Epoch = 876 Step =   31243 loss = 0.002\n",
      "Epoch = 878 Step =   31253 loss = 0.002\n",
      "Epoch = 880 Step =   31263 loss = 0.002\n",
      "Epoch = 882 Step =   31273 loss = 0.002\n",
      "Epoch = 884 Step =   31283 loss = 0.002\n",
      "Epoch = 886 Step =   31293 loss = 0.002\n",
      "Epoch = 888 Step =   31303 loss = 0.002\n",
      "Epoch = 890 Step =   31313 loss = 0.002\n",
      "Epoch = 892 Step =   31323 loss = 0.002\n",
      "INFO:tensorflow:model/global_step/sec: 7.56725\n",
      "INFO:tensorflow:Saving checkpoint to path ./trained_models\\model.ckpt\n",
      "Epoch = 894 Step =   31333 loss = 0.002\n",
      "Epoch = 896 Step =   31343 loss = 0.002\n",
      "Epoch = 898 Step =   31353 loss = 0.002\n",
      "Epoch = 900 Step =   31363 loss = 0.002\n",
      "Epoch = 902 Step =   31373 loss = 0.002\n",
      "Epoch = 904 Step =   31383 loss = 0.002\n",
      "Epoch = 906 Step =   31393 loss = 0.002\n",
      "Epoch = 908 Step =   31403 loss = 0.002\n",
      "Epoch = 910 Step =   31413 loss = 0.002\n",
      "Epoch = 912 Step =   31423 loss = 0.002\n",
      "Epoch = 914 Step =   31433 loss = 0.002\n",
      "Epoch = 916 Step =   31443 loss = 0.002\n",
      "Epoch = 918 Step =   31453 loss = 0.002\n",
      "Epoch = 920 Step =   31463 loss = 0.002\n",
      "Epoch = 922 Step =   31473 loss = 0.002\n",
      "Epoch = 924 Step =   31483 loss = 0.002\n",
      "Epoch = 926 Step =   31493 loss = 0.002\n",
      "Epoch = 928 Step =   31503 loss = 0.002\n",
      "Epoch = 930 Step =   31513 loss = 0.002\n",
      "Epoch = 932 Step =   31523 loss = 0.001\n",
      "Epoch = 934 Step =   31533 loss = 0.001\n",
      "Epoch = 936 Step =   31543 loss = 0.001\n",
      "Epoch = 938 Step =   31553 loss = 0.001\n",
      "Epoch = 940 Step =   31563 loss = 0.001\n",
      "Epoch = 942 Step =   31573 loss = 0.001\n",
      "Epoch = 944 Step =   31583 loss = 0.001\n",
      "Epoch = 946 Step =   31593 loss = 0.001\n",
      "Epoch = 948 Step =   31603 loss = 0.001\n",
      "Epoch = 950 Step =   31613 loss = 0.001\n",
      "Epoch = 952 Step =   31623 loss = 0.001\n",
      "Epoch = 954 Step =   31633 loss = 0.001\n",
      "Epoch = 956 Step =   31643 loss = 0.001\n",
      "Epoch = 958 Step =   31653 loss = 0.001\n",
      "Epoch = 960 Step =   31663 loss = 0.001\n",
      "Epoch = 962 Step =   31673 loss = 0.001\n",
      "Epoch = 964 Step =   31683 loss = 0.001\n",
      "Epoch = 966 Step =   31693 loss = 0.001\n",
      "Epoch = 968 Step =   31703 loss = 0.001\n",
      "Epoch = 970 Step =   31713 loss = 0.001\n",
      "Epoch = 972 Step =   31723 loss = 0.001\n",
      "Epoch = 974 Step =   31733 loss = 0.001\n",
      "Epoch = 976 Step =   31743 loss = 0.001\n",
      "Epoch = 978 Step =   31753 loss = 0.001\n",
      "Epoch = 980 Step =   31763 loss = 0.001\n",
      "Epoch = 982 Step =   31773 loss = 0.001\n",
      "Epoch = 984 Step =   31783 loss = 0.001\n",
      "Epoch = 986 Step =   31793 loss = 0.001\n",
      "Epoch = 988 Step =   31803 loss = 0.001\n",
      "Epoch = 990 Step =   31813 loss = 0.001\n",
      "Epoch = 992 Step =   31823 loss = 0.001\n",
      "Epoch = 994 Step =   31833 loss = 0.001\n",
      "Epoch = 996 Step =   31843 loss = 0.001\n",
      "Epoch = 998 Step =   31853 loss = 0.001\n",
      "Epoch = 1000 Step =   31863 loss = 0.001\n",
      "Epoch = 1003 Step =   31873 loss = 0.001\n",
      "Epoch = 1005 Step =   31883 loss = 0.001\n",
      "Epoch = 1007 Step =   31893 loss = 0.001\n",
      "Epoch = 1009 Step =   31903 loss = 0.001\n",
      "Epoch = 1011 Step =   31913 loss = 0.001\n",
      "Epoch = 1013 Step =   31923 loss = 0.001\n",
      "Epoch = 1015 Step =   31933 loss = 0.001\n",
      "Epoch = 1017 Step =   31943 loss = 0.001\n",
      "Epoch = 1019 Step =   31953 loss = 0.001\n",
      "Epoch = 1021 Step =   31963 loss = 0.001\n",
      "Epoch = 1023 Step =   31973 loss = 0.001\n",
      "Epoch = 1025 Step =   31983 loss = 0.001\n",
      "Epoch = 1027 Step =   31993 loss = 0.001\n",
      "Epoch = 1029 Step =   32003 loss = 0.001\n",
      "Epoch = 1031 Step =   32013 loss = 0.001\n",
      "Epoch = 1033 Step =   32023 loss = 0.001\n",
      "Epoch = 1035 Step =   32033 loss = 0.001\n",
      "Epoch = 1037 Step =   32043 loss = 0.001\n",
      "Epoch = 1039 Step =   32053 loss = 0.001\n",
      "Epoch = 1041 Step =   32063 loss = 0.001\n",
      "Epoch = 1043 Step =   32073 loss = 0.001\n",
      "Epoch = 1045 Step =   32083 loss = 0.001\n",
      "Epoch = 1047 Step =   32093 loss = 0.001\n",
      "Epoch = 1049 Step =   32103 loss = 0.001\n",
      "Epoch = 1051 Step =   32113 loss = 0.001\n",
      "Epoch = 1053 Step =   32123 loss = 0.001\n",
      "Epoch = 1055 Step =   32133 loss = 0.001\n",
      "Epoch = 1057 Step =   32143 loss = 0.001\n",
      "Epoch = 1059 Step =   32153 loss = 0.001\n",
      "Epoch = 1061 Step =   32163 loss = 0.001\n",
      "Epoch = 1063 Step =   32173 loss = 0.001\n",
      "Epoch = 1065 Step =   32183 loss = 0.001\n",
      "Epoch = 1067 Step =   32193 loss = 0.001\n",
      "Epoch = 1069 Step =   32203 loss = 0.001\n",
      "Epoch = 1071 Step =   32213 loss = 0.001\n",
      "Epoch = 1073 Step =   32223 loss = 0.001\n",
      "INFO:tensorflow:model/global_step/sec: 7.46612\n",
      "Epoch = 1075 Step =   32233 loss = 0.001\n",
      "Epoch = 1077 Step =   32243 loss = 0.001\n",
      "Epoch = 1079 Step =   32253 loss = 0.001\n",
      "Epoch = 1081 Step =   32263 loss = 0.001\n",
      "Epoch = 1083 Step =   32273 loss = 0.001\n",
      "Epoch = 1085 Step =   32283 loss = 0.001\n",
      "Epoch = 1087 Step =   32293 loss = 0.001\n",
      "Epoch = 1089 Step =   32303 loss = 0.001\n",
      "Epoch = 1091 Step =   32313 loss = 0.001\n",
      "Epoch = 1093 Step =   32323 loss = 0.001\n",
      "Epoch = 1095 Step =   32333 loss = 0.001\n",
      "Epoch = 1097 Step =   32343 loss = 0.001\n",
      "Epoch = 1099 Step =   32353 loss = 0.001\n",
      "Epoch = 1101 Step =   32363 loss = 0.001\n",
      "Epoch = 1103 Step =   32373 loss = 0.001\n",
      "Epoch = 1105 Step =   32383 loss = 0.001\n",
      "Epoch = 1107 Step =   32393 loss = 0.001\n",
      "Epoch = 1109 Step =   32403 loss = 0.001\n",
      "Epoch = 1111 Step =   32413 loss = 0.001\n",
      "Epoch = 1113 Step =   32423 loss = 0.001\n",
      "Epoch = 1115 Step =   32433 loss = 0.001\n",
      "Epoch = 1117 Step =   32443 loss = 0.001\n",
      "Epoch = 1119 Step =   32453 loss = 0.001\n",
      "Epoch = 1121 Step =   32463 loss = 0.001\n",
      "Epoch = 1123 Step =   32473 loss = 0.001\n",
      "Epoch = 1125 Step =   32483 loss = 0.001\n",
      "Epoch = 1127 Step =   32493 loss = 0.001\n",
      "Epoch = 1129 Step =   32503 loss = 0.001\n",
      "Epoch = 1131 Step =   32513 loss = 0.001\n",
      "Epoch = 1133 Step =   32523 loss = 0.001\n",
      "Epoch = 1135 Step =   32533 loss = 0.001\n",
      "Epoch = 1137 Step =   32543 loss = 0.001\n",
      "Epoch = 1139 Step =   32553 loss = 0.001\n",
      "Epoch = 1141 Step =   32563 loss = 0.001\n",
      "Epoch = 1143 Step =   32573 loss = 0.001\n",
      "Epoch = 1145 Step =   32583 loss = 0.001\n",
      "Epoch = 1147 Step =   32593 loss = 0.001\n",
      "Epoch = 1149 Step =   32603 loss = 0.001\n",
      "Epoch = 1151 Step =   32613 loss = 0.001\n",
      "Epoch = 1153 Step =   32623 loss = 0.001\n",
      "Epoch = 1155 Step =   32633 loss = 0.001\n",
      "Epoch = 1157 Step =   32643 loss = 0.001\n",
      "Epoch = 1159 Step =   32653 loss = 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1161 Step =   32663 loss = 0.001\n",
      "Epoch = 1163 Step =   32673 loss = 0.001\n",
      "Epoch = 1165 Step =   32683 loss = 0.001\n",
      "Epoch = 1167 Step =   32693 loss = 0.001\n",
      "Epoch = 1169 Step =   32703 loss = 0.001\n",
      "Epoch = 1171 Step =   32713 loss = 0.001\n",
      "Epoch = 1173 Step =   32723 loss = 0.001\n",
      "Epoch = 1175 Step =   32733 loss = 0.001\n",
      "Epoch = 1177 Step =   32743 loss = 0.001\n",
      "Epoch = 1179 Step =   32753 loss = 0.001\n",
      "Epoch = 1181 Step =   32763 loss = 0.001\n",
      "Epoch = 1183 Step =   32773 loss = 0.001\n",
      "Epoch = 1185 Step =   32783 loss = 0.001\n",
      "Epoch = 1187 Step =   32793 loss = 0.001\n",
      "Epoch = 1189 Step =   32803 loss = 0.001\n",
      "Epoch = 1191 Step =   32813 loss = 0.001\n",
      "Epoch = 1193 Step =   32823 loss = 0.001\n",
      "Epoch = 1195 Step =   32833 loss = 0.001\n",
      "Epoch = 1197 Step =   32843 loss = 0.001\n",
      "Epoch = 1199 Step =   32853 loss = 0.001\n",
      "Epoch = 1201 Step =   32863 loss = 0.001\n",
      "Epoch = 1203 Step =   32873 loss = 0.001\n",
      "Epoch = 1205 Step =   32883 loss = 0.001\n",
      "Epoch = 1207 Step =   32893 loss = 0.001\n",
      "Epoch = 1209 Step =   32903 loss = 0.001\n",
      "Epoch = 1211 Step =   32913 loss = 0.001\n",
      "Epoch = 1213 Step =   32923 loss = 0.001\n",
      "Epoch = 1215 Step =   32933 loss = 0.001\n",
      "Epoch = 1217 Step =   32943 loss = 0.001\n",
      "Epoch = 1219 Step =   32953 loss = 0.001\n",
      "Epoch = 1221 Step =   32963 loss = 0.001\n",
      "Epoch = 1223 Step =   32973 loss = 0.001\n",
      "Epoch = 1225 Step =   32983 loss = 0.001\n",
      "Epoch = 1227 Step =   32993 loss = 0.001\n",
      "Epoch = 1229 Step =   33003 loss = 0.001\n",
      "Epoch = 1231 Step =   33013 loss = 0.001\n",
      "Epoch = 1233 Step =   33023 loss = 0.001\n",
      "Epoch = 1235 Step =   33033 loss = 0.001\n",
      "Epoch = 1237 Step =   33043 loss = 0.001\n",
      "Epoch = 1239 Step =   33053 loss = 0.001\n",
      "Epoch = 1241 Step =   33063 loss = 0.001\n",
      "Epoch = 1243 Step =   33073 loss = 0.001\n",
      "Epoch = 1245 Step =   33083 loss = 0.001\n",
      "Epoch = 1247 Step =   33093 loss = 0.001\n",
      "Epoch = 1249 Step =   33103 loss = 0.001\n",
      "Epoch = 1251 Step =   33113 loss = 0.001\n",
      "Epoch = 1253 Step =   33123 loss = 0.001\n",
      "INFO:tensorflow:model/global_step/sec: 7.50892\n",
      "Epoch = 1255 Step =   33133 loss = 0.001\n",
      "Epoch = 1257 Step =   33143 loss = 0.001\n",
      "Epoch = 1259 Step =   33153 loss = 0.001\n",
      "Epoch = 1261 Step =   33163 loss = 0.001\n",
      "Epoch = 1263 Step =   33173 loss = 0.001\n",
      "Epoch = 1265 Step =   33183 loss = 0.001\n",
      "Epoch = 1267 Step =   33193 loss = 0.001\n",
      "Epoch = 1269 Step =   33203 loss = 0.001\n",
      "Epoch = 1271 Step =   33213 loss = 0.001\n",
      "Epoch = 1273 Step =   33223 loss = 0.001\n",
      "Epoch = 1275 Step =   33233 loss = 0.001\n",
      "Epoch = 1277 Step =   33243 loss = 0.001\n",
      "Epoch = 1279 Step =   33253 loss = 0.001\n",
      "Epoch = 1281 Step =   33263 loss = 0.001\n",
      "Epoch = 1283 Step =   33273 loss = 0.001\n",
      "Epoch = 1285 Step =   33283 loss = 0.001\n",
      "Epoch = 1287 Step =   33293 loss = 0.001\n",
      "Epoch = 1289 Step =   33303 loss = 0.001\n",
      "Epoch = 1291 Step =   33313 loss = 0.001\n",
      "Epoch = 1293 Step =   33323 loss = 0.001\n",
      "Epoch = 1295 Step =   33333 loss = 0.001\n",
      "Epoch = 1297 Step =   33343 loss = 0.001\n",
      "Epoch = 1299 Step =   33353 loss = 0.001\n",
      "Epoch = 1301 Step =   33363 loss = 0.001\n",
      "Epoch = 1303 Step =   33373 loss = 0.001\n",
      "Epoch = 1305 Step =   33383 loss = 0.001\n",
      "Epoch = 1307 Step =   33393 loss = 0.001\n",
      "Epoch = 1309 Step =   33403 loss = 0.001\n",
      "Epoch = 1311 Step =   33413 loss = 0.001\n",
      "Epoch = 1313 Step =   33423 loss = 0.001\n",
      "Epoch = 1315 Step =   33433 loss = 0.001\n",
      "Epoch = 1317 Step =   33443 loss = 0.001\n",
      "Epoch = 1319 Step =   33453 loss = 0.001\n",
      "Epoch = 1321 Step =   33463 loss = 0.001\n",
      "Epoch = 1323 Step =   33473 loss = 0.001\n",
      "Epoch = 1325 Step =   33483 loss = 0.001\n",
      "Epoch = 1327 Step =   33493 loss = 0.001\n",
      "Epoch = 1329 Step =   33503 loss = 0.001\n",
      "Epoch = 1331 Step =   33513 loss = 0.001\n",
      "Epoch = 1333 Step =   33523 loss = 0.001\n",
      "Epoch = 1335 Step =   33533 loss = 0.001\n",
      "Epoch = 1337 Step =   33543 loss = 0.001\n",
      "Epoch = 1339 Step =   33553 loss = 0.001\n",
      "Epoch = 1341 Step =   33563 loss = 0.001\n",
      "Epoch = 1343 Step =   33573 loss = 0.001\n",
      "Epoch = 1345 Step =   33583 loss = 0.001\n",
      "Epoch = 1347 Step =   33593 loss = 0.001\n",
      "Epoch = 1349 Step =   33603 loss = 0.001\n",
      "Epoch = 1351 Step =   33613 loss = 0.001\n",
      "Epoch = 1353 Step =   33623 loss = 0.001\n",
      "Epoch = 1355 Step =   33633 loss = 0.001\n",
      "Epoch = 1357 Step =   33643 loss = 0.001\n",
      "Epoch = 1359 Step =   33653 loss = 0.001\n",
      "Epoch = 1361 Step =   33663 loss = 0.001\n",
      "Epoch = 1363 Step =   33673 loss = 0.001\n",
      "Epoch = 1365 Step =   33683 loss = 0.001\n",
      "Epoch = 1367 Step =   33693 loss = 0.001\n",
      "Epoch = 1369 Step =   33703 loss = 0.001\n",
      "Epoch = 1371 Step =   33713 loss = 0.001\n",
      "Epoch = 1373 Step =   33723 loss = 0.001\n",
      "Epoch = 1375 Step =   33733 loss = 0.001\n",
      "Epoch = 1377 Step =   33743 loss = 0.001\n",
      "Epoch = 1379 Step =   33753 loss = 0.001\n",
      "Epoch = 1381 Step =   33763 loss = 0.001\n",
      "Epoch = 1383 Step =   33773 loss = 0.001\n",
      "Epoch = 1385 Step =   33783 loss = 0.001\n",
      "Epoch = 1387 Step =   33793 loss = 0.001\n",
      "Epoch = 1389 Step =   33803 loss = 0.001\n",
      "Epoch = 1391 Step =   33813 loss = 0.001\n",
      "Epoch = 1393 Step =   33823 loss = 0.001\n",
      "Epoch = 1395 Step =   33833 loss = 0.001\n",
      "Epoch = 1397 Step =   33843 loss = 0.001\n",
      "Epoch = 1399 Step =   33853 loss = 0.001\n",
      "Epoch = 1401 Step =   33863 loss = 0.001\n",
      "Epoch = 1403 Step =   33873 loss = 0.001\n",
      "Epoch = 1405 Step =   33883 loss = 0.001\n",
      "Epoch = 1407 Step =   33893 loss = 0.001\n",
      "Epoch = 1409 Step =   33903 loss = 0.001\n",
      "Epoch = 1411 Step =   33913 loss = 0.001\n",
      "Epoch = 1413 Step =   33923 loss = 0.001\n",
      "Epoch = 1415 Step =   33933 loss = 0.001\n",
      "Epoch = 1417 Step =   33943 loss = 0.001\n",
      "Epoch = 1419 Step =   33953 loss = 0.001\n",
      "Epoch = 1421 Step =   33963 loss = 0.001\n",
      "Epoch = 1423 Step =   33973 loss = 0.001\n",
      "Epoch = 1425 Step =   33983 loss = 0.001\n",
      "Epoch = 1427 Step =   33993 loss = 0.001\n",
      "Epoch = 1429 Step =   34003 loss = 0.001\n",
      "Epoch = 1431 Step =   34013 loss = 0.001\n",
      "Epoch = 1433 Step =   34023 loss = 0.001\n",
      "INFO:tensorflow:model/global_step/sec: 7.50755\n",
      "Epoch = 1435 Step =   34033 loss = 0.001\n",
      "Epoch = 1437 Step =   34043 loss = 0.001\n",
      "Epoch = 1439 Step =   34053 loss = 0.001\n",
      "Epoch = 1441 Step =   34063 loss = 0.001\n",
      "Epoch = 1443 Step =   34073 loss = 0.001\n",
      "Epoch = 1445 Step =   34083 loss = 0.001\n",
      "Epoch = 1447 Step =   34093 loss = 0.001\n",
      "Epoch = 1449 Step =   34103 loss = 0.001\n",
      "Epoch = 1451 Step =   34113 loss = 0.001\n",
      "Epoch = 1453 Step =   34123 loss = 0.001\n",
      "Epoch = 1455 Step =   34133 loss = 0.001\n",
      "Epoch = 1457 Step =   34143 loss = 0.001\n",
      "Epoch = 1459 Step =   34153 loss = 0.001\n",
      "Epoch = 1461 Step =   34163 loss = 0.001\n",
      "Epoch = 1463 Step =   34173 loss = 0.001\n",
      "Epoch = 1465 Step =   34183 loss = 0.001\n",
      "Epoch = 1467 Step =   34193 loss = 0.001\n",
      "Epoch = 1469 Step =   34203 loss = 0.001\n",
      "Epoch = 1471 Step =   34213 loss = 0.001\n",
      "Epoch = 1473 Step =   34223 loss = 0.001\n",
      "Epoch = 1475 Step =   34233 loss = 0.001\n",
      "Epoch = 1477 Step =   34243 loss = 0.001\n",
      "Epoch = 1479 Step =   34253 loss = 0.001\n",
      "Epoch = 1481 Step =   34263 loss = 0.001\n",
      "Epoch = 1483 Step =   34273 loss = 0.001\n",
      "Epoch = 1485 Step =   34283 loss = 0.001\n",
      "Epoch = 1487 Step =   34293 loss = 0.001\n",
      "Epoch = 1489 Step =   34303 loss = 0.001\n",
      "Epoch = 1491 Step =   34313 loss = 0.001\n",
      "Epoch = 1493 Step =   34323 loss = 0.001\n",
      "Epoch = 1495 Step =   34333 loss = 0.001\n",
      "Epoch = 1497 Step =   34343 loss = 0.001\n",
      "Epoch = 1499 Step =   34353 loss = 0.001\n",
      "Epoch = 1502 Step =   34363 loss = 0.001\n",
      "Epoch = 1504 Step =   34373 loss = 0.001\n",
      "Epoch = 1506 Step =   34383 loss = 0.001\n",
      "Epoch = 1508 Step =   34393 loss = 0.001\n",
      "Epoch = 1510 Step =   34403 loss = 0.001\n",
      "Epoch = 1512 Step =   34413 loss = 0.001\n",
      "Epoch = 1514 Step =   34423 loss = 0.001\n",
      "Epoch = 1516 Step =   34433 loss = 0.001\n",
      "Epoch = 1518 Step =   34443 loss = 0.001\n",
      "Epoch = 1520 Step =   34453 loss = 0.001\n",
      "Epoch = 1522 Step =   34463 loss = 0.001\n",
      "Epoch = 1524 Step =   34473 loss = 0.001\n",
      "Epoch = 1526 Step =   34483 loss = 0.001\n",
      "Epoch = 1528 Step =   34493 loss = 0.001\n",
      "Epoch = 1530 Step =   34503 loss = 0.001\n",
      "Epoch = 1532 Step =   34513 loss = 0.001\n",
      "Epoch = 1534 Step =   34523 loss = 0.001\n",
      "Epoch = 1536 Step =   34533 loss = 0.001\n",
      "Epoch = 1538 Step =   34543 loss = 0.001\n",
      "Epoch = 1540 Step =   34553 loss = 0.001\n",
      "Epoch = 1542 Step =   34563 loss = 0.001\n",
      "Epoch = 1544 Step =   34573 loss = 0.001\n",
      "Epoch = 1546 Step =   34583 loss = 0.001\n",
      "Epoch = 1548 Step =   34593 loss = 0.001\n",
      "Epoch = 1550 Step =   34603 loss = 0.001\n",
      "Epoch = 1552 Step =   34613 loss = 0.001\n",
      "Epoch = 1554 Step =   34623 loss = 0.001\n",
      "Epoch = 1556 Step =   34633 loss = 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1558 Step =   34643 loss = 0.001\n",
      "Epoch = 1560 Step =   34653 loss = 0.001\n",
      "Epoch = 1562 Step =   34663 loss = 0.001\n",
      "Epoch = 1564 Step =   34673 loss = 0.001\n",
      "Epoch = 1566 Step =   34683 loss = 0.001\n",
      "Epoch = 1568 Step =   34693 loss = 0.001\n",
      "Epoch = 1570 Step =   34703 loss = 0.001\n",
      "Epoch = 1572 Step =   34713 loss = 0.001\n",
      "Epoch = 1574 Step =   34723 loss = 0.001\n",
      "Epoch = 1576 Step =   34733 loss = 0.001\n",
      "Epoch = 1578 Step =   34743 loss = 0.001\n",
      "Epoch = 1580 Step =   34753 loss = 0.001\n",
      "Epoch = 1582 Step =   34763 loss = 0.001\n",
      "Epoch = 1584 Step =   34773 loss = 0.001\n",
      "Epoch = 1586 Step =   34783 loss = 0.001\n",
      "Epoch = 1588 Step =   34793 loss = 0.001\n",
      "Epoch = 1590 Step =   34803 loss = 0.001\n",
      "Epoch = 1592 Step =   34813 loss = 0.001\n",
      "Epoch = 1594 Step =   34823 loss = 0.001\n",
      "Epoch = 1596 Step =   34833 loss = 0.001\n",
      "Epoch = 1598 Step =   34843 loss = 0.001\n",
      "Epoch = 1600 Step =   34853 loss = 0.001\n",
      "Epoch = 1602 Step =   34863 loss = 0.001\n",
      "Epoch = 1604 Step =   34873 loss = 0.001\n",
      "Epoch = 1606 Step =   34883 loss = 0.001\n",
      "Epoch = 1608 Step =   34893 loss = 0.001\n",
      "Epoch = 1610 Step =   34903 loss = 0.001\n",
      "INFO:tensorflow:model/global_step/sec: 7.33416\n",
      "Epoch = 1612 Step =   34913 loss = 0.001\n",
      "Epoch = 1614 Step =   34923 loss = 0.001\n",
      "Epoch = 1616 Step =   34933 loss = 0.001\n",
      "Epoch = 1618 Step =   34943 loss = 0.001\n",
      "Epoch = 1620 Step =   34953 loss = 0.001\n",
      "Epoch = 1622 Step =   34963 loss = 0.001\n",
      "Epoch = 1624 Step =   34973 loss = 0.001\n",
      "Epoch = 1626 Step =   34983 loss = 0.001\n",
      "Epoch = 1628 Step =   34993 loss = 0.001\n",
      "Epoch = 1630 Step =   35003 loss = 0.001\n",
      "Epoch = 1632 Step =   35013 loss = 0.001\n",
      "Epoch = 1634 Step =   35023 loss = 0.001\n",
      "Epoch = 1636 Step =   35033 loss = 0.001\n",
      "Epoch = 1638 Step =   35043 loss = 0.001\n",
      "Epoch = 1640 Step =   35053 loss = 0.001\n",
      "Epoch = 1642 Step =   35063 loss = 0.001\n",
      "Epoch = 1644 Step =   35073 loss = 0.001\n",
      "Epoch = 1646 Step =   35083 loss = 0.001\n",
      "Epoch = 1648 Step =   35093 loss = 0.001\n",
      "Epoch = 1650 Step =   35103 loss = 0.001\n",
      "Epoch = 1652 Step =   35113 loss = 0.001\n",
      "Epoch = 1654 Step =   35123 loss = 0.001\n",
      "Epoch = 1656 Step =   35133 loss = 0.001\n",
      "Epoch = 1658 Step =   35143 loss = 0.001\n",
      "Epoch = 1660 Step =   35153 loss = 0.001\n",
      "Epoch = 1662 Step =   35163 loss = 0.001\n",
      "Epoch = 1664 Step =   35173 loss = 0.001\n",
      "Epoch = 1666 Step =   35183 loss = 0.001\n",
      "Epoch = 1668 Step =   35193 loss = 0.001\n",
      "Epoch = 1670 Step =   35203 loss = 0.001\n",
      "Epoch = 1672 Step =   35213 loss = 0.001\n",
      "Epoch = 1674 Step =   35223 loss = 0.001\n",
      "Epoch = 1676 Step =   35233 loss = 0.001\n",
      "Epoch = 1678 Step =   35243 loss = 0.001\n",
      "Epoch = 1680 Step =   35253 loss = 0.001\n",
      "Epoch = 1682 Step =   35263 loss = 0.001\n",
      "Epoch = 1684 Step =   35273 loss = 0.001\n",
      "Epoch = 1686 Step =   35283 loss = 0.001\n",
      "Epoch = 1688 Step =   35293 loss = 0.001\n",
      "Epoch = 1690 Step =   35303 loss = 0.001\n",
      "Epoch = 1692 Step =   35313 loss = 0.001\n",
      "Epoch = 1694 Step =   35323 loss = 0.001\n",
      "Epoch = 1696 Step =   35333 loss = 0.001\n",
      "Epoch = 1698 Step =   35343 loss = 0.001\n",
      "Epoch = 1700 Step =   35353 loss = 0.001\n",
      "Epoch = 1702 Step =   35363 loss = 0.001\n",
      "Epoch = 1704 Step =   35373 loss = 0.001\n",
      "Epoch = 1706 Step =   35383 loss = 0.001\n",
      "Epoch = 1708 Step =   35393 loss = 0.001\n",
      "Epoch = 1710 Step =   35403 loss = 0.001\n",
      "Epoch = 1712 Step =   35413 loss = 0.001\n",
      "Epoch = 1714 Step =   35423 loss = 0.001\n",
      "Epoch = 1716 Step =   35433 loss = 0.001\n",
      "Epoch = 1718 Step =   35443 loss = 0.001\n",
      "Epoch = 1720 Step =   35453 loss = 0.001\n",
      "Epoch = 1722 Step =   35463 loss = 0.001\n",
      "Epoch = 1724 Step =   35473 loss = 0.001\n",
      "Epoch = 1726 Step =   35483 loss = 0.001\n",
      "Epoch = 1728 Step =   35493 loss = 0.001\n",
      "Epoch = 1730 Step =   35503 loss = 0.001\n",
      "Epoch = 1732 Step =   35513 loss = 0.001\n",
      "Epoch = 1734 Step =   35523 loss = 0.001\n",
      "Epoch = 1736 Step =   35533 loss = 0.001\n",
      "Epoch = 1738 Step =   35543 loss = 0.001\n",
      "Epoch = 1740 Step =   35553 loss = 0.001\n",
      "Epoch = 1742 Step =   35563 loss = 0.001\n",
      "Epoch = 1744 Step =   35573 loss = 0.001\n",
      "Epoch = 1746 Step =   35583 loss = 0.001\n",
      "Epoch = 1748 Step =   35593 loss = 0.001\n",
      "Epoch = 1750 Step =   35603 loss = 0.001\n",
      "Epoch = 1752 Step =   35613 loss = 0.001\n",
      "INFO:tensorflow:Saving checkpoint to path ./trained_models\\model.ckpt\n",
      "Epoch = 1754 Step =   35623 loss = 0.001\n",
      "Epoch = 1756 Step =   35633 loss = 0.001\n",
      "Epoch = 1758 Step =   35643 loss = 0.001\n",
      "Epoch = 1760 Step =   35653 loss = 0.001\n",
      "Epoch = 1762 Step =   35663 loss = 0.001\n",
      "Epoch = 1764 Step =   35673 loss = 0.001\n",
      "Epoch = 1766 Step =   35683 loss = 0.001\n",
      "Epoch = 1768 Step =   35693 loss = 0.001\n",
      "Epoch = 1770 Step =   35703 loss = 0.001\n",
      "Epoch = 1772 Step =   35713 loss = 0.001\n",
      "Epoch = 1774 Step =   35723 loss = 0.001\n",
      "Epoch = 1776 Step =   35733 loss = 0.001\n",
      "Epoch = 1778 Step =   35743 loss = 0.001\n",
      "Epoch = 1780 Step =   35753 loss = 0.001\n",
      "Epoch = 1782 Step =   35763 loss = 0.001\n",
      "Epoch = 1784 Step =   35773 loss = 0.001\n",
      "Epoch = 1786 Step =   35783 loss = 0.001\n",
      "Epoch = 1788 Step =   35793 loss = 0.001\n",
      "Epoch = 1790 Step =   35803 loss = 0.001\n",
      "Epoch = 1792 Step =   35813 loss = 0.001\n",
      "Epoch = 1794 Step =   35823 loss = 0.001\n",
      "Epoch = 1796 Step =   35833 loss = 0.001\n",
      "Epoch = 1798 Step =   35843 loss = 0.001\n",
      "Epoch = 1800 Step =   35853 loss = 0.001\n",
      "Epoch = 1802 Step =   35863 loss = 0.001\n",
      "Epoch = 1804 Step =   35873 loss = 0.001\n",
      "Epoch = 1806 Step =   35883 loss = 0.001\n",
      "Epoch = 1808 Step =   35893 loss = 0.001\n",
      "Epoch = 1810 Step =   35903 loss = 0.001\n",
      "Epoch = 1812 Step =   35913 loss = 0.001\n",
      "Epoch = 1814 Step =   35923 loss = 0.001\n",
      "Epoch = 1816 Step =   35933 loss = 0.001\n",
      "Epoch = 1818 Step =   35943 loss = 0.001\n",
      "Epoch = 1820 Step =   35953 loss = 0.001\n",
      "Epoch = 1822 Step =   35963 loss = 0.001\n",
      "Epoch = 1824 Step =   35973 loss = 0.001\n",
      "Epoch = 1826 Step =   35983 loss = 0.001\n",
      "Epoch = 1828 Step =   35993 loss = 0.001\n",
      "Epoch = 1830 Step =   36003 loss = 0.001\n",
      "Epoch = 1832 Step =   36013 loss = 0.001\n",
      "Epoch = 1834 Step =   36023 loss = 0.001\n",
      "Epoch = 1836 Step =   36033 loss = 0.001\n",
      "Epoch = 1838 Step =   36043 loss = 0.001\n",
      "Epoch = 1840 Step =   36053 loss = 0.001\n",
      "Epoch = 1842 Step =   36063 loss = 0.001\n",
      "Epoch = 1844 Step =   36073 loss = 0.001\n",
      "Epoch = 1846 Step =   36083 loss = 0.001\n",
      "Epoch = 1848 Step =   36093 loss = 0.001\n",
      "Epoch = 1850 Step =   36103 loss = 0.001\n",
      "Epoch = 1852 Step =   36113 loss = 0.001\n",
      "Epoch = 1854 Step =   36123 loss = 0.001\n",
      "Epoch = 1856 Step =   36133 loss = 0.001\n",
      "Epoch = 1858 Step =   36143 loss = 0.001\n",
      "Epoch = 1860 Step =   36153 loss = 0.001\n",
      "Epoch = 1862 Step =   36163 loss = 0.001\n",
      "Epoch = 1864 Step =   36173 loss = 0.001\n",
      "Epoch = 1866 Step =   36183 loss = 0.001\n",
      "Epoch = 1868 Step =   36193 loss = 0.001\n",
      "Epoch = 1870 Step =   36203 loss = 0.001\n",
      "Epoch = 1872 Step =   36213 loss = 0.001\n",
      "Epoch = 1874 Step =   36223 loss = 0.001\n",
      "Epoch = 1876 Step =   36233 loss = 0.001\n",
      "Epoch = 1878 Step =   36243 loss = 0.001\n",
      "Epoch = 1880 Step =   36253 loss = 0.001\n",
      "Epoch = 1882 Step =   36263 loss = 0.001\n",
      "Epoch = 1884 Step =   36273 loss = 0.001\n",
      "Epoch = 1886 Step =   36283 loss = 0.001\n",
      "Epoch = 1888 Step =   36293 loss = 0.001\n",
      "Epoch = 1890 Step =   36303 loss = 0.001\n",
      "Epoch = 1892 Step =   36313 loss = 0.001\n",
      "Epoch = 1894 Step =   36323 loss = 0.001\n",
      "Epoch = 1896 Step =   36333 loss = 0.001\n",
      "Epoch = 1898 Step =   36343 loss = 0.001\n",
      "Epoch = 1900 Step =   36353 loss = 0.001\n",
      "Epoch = 1902 Step =   36363 loss = 0.001\n",
      "Epoch = 1904 Step =   36373 loss = 0.001\n",
      "Epoch = 1906 Step =   36383 loss = 0.001\n",
      "Epoch = 1908 Step =   36393 loss = 0.001\n",
      "Epoch = 1910 Step =   36403 loss = 0.001\n",
      "Epoch = 1912 Step =   36413 loss = 0.001\n",
      "Epoch = 1914 Step =   36423 loss = 0.001\n",
      "Epoch = 1916 Step =   36433 loss = 0.001\n",
      "Epoch = 1918 Step =   36443 loss = 0.001\n",
      "Epoch = 1920 Step =   36453 loss = 0.001\n",
      "Epoch = 1922 Step =   36463 loss = 0.001\n",
      "Epoch = 1924 Step =   36473 loss = 0.001\n",
      "Epoch = 1926 Step =   36483 loss = 0.001\n",
      "Epoch = 1928 Step =   36493 loss = 0.001\n",
      "Epoch = 1930 Step =   36503 loss = 0.001\n",
      "Epoch = 1932 Step =   36513 loss = 0.001\n",
      "Epoch = 1934 Step =   36523 loss = 0.001\n",
      "Epoch = 1936 Step =   36533 loss = 0.001\n",
      "Epoch = 1938 Step =   36543 loss = 0.001\n",
      "Epoch = 1940 Step =   36553 loss = 0.001\n",
      "Epoch = 1942 Step =   36563 loss = 0.001\n",
      "Epoch = 1944 Step =   36573 loss = 0.001\n",
      "Epoch = 1946 Step =   36583 loss = 0.001\n",
      "Epoch = 1948 Step =   36593 loss = 0.001\n",
      "Epoch = 1950 Step =   36603 loss = 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1952 Step =   36613 loss = 0.001\n",
      "Epoch = 1954 Step =   36623 loss = 0.001\n",
      "Epoch = 1956 Step =   36633 loss = 0.001\n",
      "Epoch = 1958 Step =   36643 loss = 0.001\n",
      "Epoch = 1960 Step =   36653 loss = 0.001\n",
      "Epoch = 1962 Step =   36663 loss = 0.001\n",
      "Epoch = 1964 Step =   36673 loss = 0.001\n",
      "Epoch = 1966 Step =   36683 loss = 0.001\n",
      "Epoch = 1968 Step =   36693 loss = 0.001\n",
      "Epoch = 1970 Step =   36703 loss = 0.001\n",
      "Epoch = 1972 Step =   36713 loss = 0.001\n",
      "Epoch = 1974 Step =   36723 loss = 0.001\n",
      "Epoch = 1976 Step =   36733 loss = 0.001\n",
      "Epoch = 1978 Step =   36743 loss = 0.001\n",
      "Epoch = 1980 Step =   36753 loss = 0.001\n",
      "Epoch = 1982 Step =   36763 loss = 0.001\n",
      "Epoch = 1984 Step =   36773 loss = 0.001\n",
      "Epoch = 1986 Step =   36783 loss = 0.001\n",
      "Epoch = 1988 Step =   36793 loss = 0.001\n",
      "Epoch = 1990 Step =   36803 loss = 0.001\n",
      "Epoch = 1992 Step =   36813 loss = 0.001\n",
      "Epoch = 1994 Step =   36823 loss = 0.001\n",
      "Epoch = 1996 Step =   36833 loss = 0.001\n",
      "Epoch = 1998 Step =   36843 loss = 0.001\n",
      "Epoch = 2000 Step =   36853 loss = 0.001\n",
      "Epoch = 2003 Step =   36863 loss = 0.001\n",
      "Epoch = 2005 Step =   36873 loss = 0.001\n",
      "Epoch = 2007 Step =   36883 loss = 0.001\n",
      "Epoch = 2009 Step =   36893 loss = 0.001\n",
      "Epoch = 2011 Step =   36903 loss = 0.001\n",
      "Epoch = 2013 Step =   36913 loss = 0.001\n",
      "Epoch = 2015 Step =   36923 loss = 0.001\n",
      "Epoch = 2017 Step =   36933 loss = 0.001\n",
      "Epoch = 2019 Step =   36943 loss = 0.001\n",
      "Epoch = 2021 Step =   36953 loss = 0.001\n",
      "Epoch = 2023 Step =   36963 loss = 0.001\n",
      "Epoch = 2025 Step =   36973 loss = 0.001\n",
      "Epoch = 2027 Step =   36983 loss = 0.001\n",
      "Epoch = 2029 Step =   36993 loss = 0.001\n",
      "Epoch = 2031 Step =   37003 loss = 0.001\n",
      "Epoch = 2033 Step =   37013 loss = 0.001\n",
      "Epoch = 2035 Step =   37023 loss = 0.001\n",
      "Epoch = 2037 Step =   37033 loss = 0.001\n",
      "Epoch = 2039 Step =   37043 loss = 0.001\n",
      "Epoch = 2041 Step =   37053 loss = 0.001\n",
      "Epoch = 2043 Step =   37063 loss = 0.001\n",
      "Epoch = 2045 Step =   37073 loss = 0.001\n",
      "Epoch = 2047 Step =   37083 loss = 0.001\n",
      "Epoch = 2049 Step =   37093 loss = 0.001\n",
      "Epoch = 2051 Step =   37103 loss = 0.001\n",
      "Epoch = 2053 Step =   37113 loss = 0.001\n",
      "Epoch = 2055 Step =   37123 loss = 0.001\n",
      "Epoch = 2057 Step =   37133 loss = 0.001\n",
      "Epoch = 2059 Step =   37143 loss = 0.001\n",
      "Epoch = 2061 Step =   37153 loss = 0.001\n",
      "Epoch = 2063 Step =   37163 loss = 0.001\n",
      "Epoch = 2065 Step =   37173 loss = 0.001\n",
      "Epoch = 2067 Step =   37183 loss = 0.001\n",
      "Epoch = 2069 Step =   37193 loss = 0.001\n",
      "Epoch = 2071 Step =   37203 loss = 0.001\n",
      "Epoch = 2073 Step =   37213 loss = 0.001\n",
      "Epoch = 2075 Step =   37223 loss = 0.001\n",
      "Epoch = 2077 Step =   37233 loss = 0.001\n",
      "Epoch = 2079 Step =   37243 loss = 0.001\n",
      "Epoch = 2081 Step =   37253 loss = 0.001\n",
      "Epoch = 2083 Step =   37263 loss = 0.001\n",
      "Epoch = 2085 Step =   37273 loss = 0.001\n",
      "Epoch = 2087 Step =   37283 loss = 0.001\n",
      "Epoch = 2089 Step =   37293 loss = 0.001\n",
      "Epoch = 2091 Step =   37303 loss = 0.001\n",
      "Epoch = 2093 Step =   37313 loss = 0.001\n",
      "Epoch = 2095 Step =   37323 loss = 0.001\n",
      "Epoch = 2097 Step =   37333 loss = 0.001\n",
      "Epoch = 2099 Step =   37343 loss = 0.001\n",
      "Epoch = 2101 Step =   37353 loss = 0.001\n",
      "Epoch = 2103 Step =   37363 loss = 0.001\n",
      "Epoch = 2105 Step =   37373 loss = 0.001\n",
      "Epoch = 2107 Step =   37383 loss = 0.001\n",
      "Epoch = 2109 Step =   37393 loss = 0.001\n",
      "Epoch = 2111 Step =   37403 loss = 0.001\n",
      "Epoch = 2113 Step =   37413 loss = 0.001\n",
      "Epoch = 2115 Step =   37423 loss = 0.001\n",
      "Epoch = 2117 Step =   37433 loss = 0.001\n",
      "Epoch = 2119 Step =   37443 loss = 0.001\n",
      "Epoch = 2121 Step =   37453 loss = 0.001\n",
      "Epoch = 2123 Step =   37463 loss = 0.001\n",
      "Epoch = 2125 Step =   37473 loss = 0.001\n",
      "Epoch = 2127 Step =   37483 loss = 0.001\n",
      "Epoch = 2129 Step =   37493 loss = 0.001\n",
      "Epoch = 2131 Step =   37503 loss = 0.001\n",
      "Epoch = 2133 Step =   37513 loss = 0.001\n",
      "Epoch = 2135 Step =   37523 loss = 0.001\n",
      "Epoch = 2137 Step =   37533 loss = 0.001\n",
      "Epoch = 2139 Step =   37543 loss = 0.001\n",
      "Epoch = 2141 Step =   37553 loss = 0.001\n",
      "Epoch = 2143 Step =   37563 loss = 0.001\n",
      "Epoch = 2145 Step =   37573 loss = 0.001\n",
      "Epoch = 2147 Step =   37583 loss = 0.001\n",
      "Epoch = 2149 Step =   37593 loss = 0.001\n",
      "Epoch = 2151 Step =   37603 loss = 0.001\n",
      "Epoch = 2153 Step =   37613 loss = 0.001\n",
      "Epoch = 2155 Step =   37623 loss = 0.001\n",
      "Epoch = 2157 Step =   37633 loss = 0.001\n",
      "Epoch = 2159 Step =   37643 loss = 0.001\n",
      "Epoch = 2161 Step =   37653 loss = 0.001\n",
      "Epoch = 2163 Step =   37663 loss = 0.001\n",
      "Epoch = 2165 Step =   37673 loss = 0.001\n",
      "Epoch = 2167 Step =   37683 loss = 0.001\n",
      "Epoch = 2169 Step =   37693 loss = 0.001\n",
      "Epoch = 2171 Step =   37703 loss = 0.001\n",
      "Epoch = 2173 Step =   37713 loss = 0.001\n",
      "Epoch = 2175 Step =   37723 loss = 0.001\n",
      "Epoch = 2177 Step =   37733 loss = 0.001\n",
      "Epoch = 2179 Step =   37743 loss = 0.001\n",
      "Epoch = 2181 Step =   37753 loss = 0.001\n",
      "Epoch = 2183 Step =   37763 loss = 0.001\n",
      "Epoch = 2185 Step =   37773 loss = 0.001\n",
      "Epoch = 2187 Step =   37783 loss = 0.001\n",
      "Epoch = 2189 Step =   37793 loss = 0.001\n",
      "Epoch = 2191 Step =   37803 loss = 0.001\n",
      "Epoch = 2193 Step =   37813 loss = 0.001\n",
      "Epoch = 2195 Step =   37823 loss = 0.001\n",
      "Epoch = 2197 Step =   37833 loss = 0.001\n",
      "Epoch = 2199 Step =   37843 loss = 0.001\n",
      "Epoch = 2201 Step =   37853 loss = 0.001\n",
      "Epoch = 2203 Step =   37863 loss = 0.001\n",
      "Epoch = 2205 Step =   37873 loss = 0.001\n",
      "Epoch = 2207 Step =   37883 loss = 0.001\n",
      "Epoch = 2209 Step =   37893 loss = 0.001\n",
      "Epoch = 2211 Step =   37903 loss = 0.001\n",
      "Epoch = 2213 Step =   37913 loss = 0.001\n",
      "Epoch = 2215 Step =   37923 loss = 0.001\n",
      "Epoch = 2217 Step =   37933 loss = 0.001\n",
      "Epoch = 2219 Step =   37943 loss = 0.001\n",
      "Epoch = 2221 Step =   37953 loss = 0.001\n",
      "Epoch = 2223 Step =   37963 loss = 0.001\n",
      "Epoch = 2225 Step =   37973 loss = 0.001\n",
      "Epoch = 2227 Step =   37983 loss = 0.001\n",
      "Epoch = 2229 Step =   37993 loss = 0.001\n",
      "Epoch = 2231 Step =   38003 loss = 0.001\n",
      "Epoch = 2233 Step =   38013 loss = 0.001\n",
      "Epoch = 2235 Step =   38023 loss = 0.001\n",
      "Epoch = 2237 Step =   38033 loss = 0.001\n",
      "Epoch = 2239 Step =   38043 loss = 0.001\n",
      "Epoch = 2241 Step =   38053 loss = 0.001\n",
      "Epoch = 2243 Step =   38063 loss = 0.001\n",
      "Epoch = 2245 Step =   38073 loss = 0.001\n",
      "Epoch = 2247 Step =   38083 loss = 0.001\n",
      "Epoch = 2249 Step =   38093 loss = 0.001\n",
      "Epoch = 2251 Step =   38103 loss = 0.001\n",
      "Epoch = 2253 Step =   38113 loss = 0.001\n",
      "Epoch = 2255 Step =   38123 loss = 0.001\n",
      "Epoch = 2257 Step =   38133 loss = 0.001\n",
      "Epoch = 2259 Step =   38143 loss = 0.001\n",
      "Epoch = 2261 Step =   38153 loss = 0.001\n",
      "Epoch = 2263 Step =   38163 loss = 0.001\n",
      "Epoch = 2265 Step =   38173 loss = 0.001\n",
      "Epoch = 2267 Step =   38183 loss = 0.001\n",
      "Epoch = 2269 Step =   38193 loss = 0.001\n",
      "Epoch = 2271 Step =   38203 loss = 0.001\n",
      "Epoch = 2273 Step =   38213 loss = 0.001\n",
      "Epoch = 2275 Step =   38223 loss = 0.001\n",
      "Epoch = 2277 Step =   38233 loss = 0.001\n",
      "Epoch = 2279 Step =   38243 loss = 0.001\n",
      "Epoch = 2281 Step =   38253 loss = 0.001\n",
      "Epoch = 2283 Step =   38263 loss = 0.001\n",
      "Epoch = 2285 Step =   38273 loss = 0.001\n",
      "Epoch = 2287 Step =   38283 loss = 0.001\n",
      "Epoch = 2289 Step =   38293 loss = 0.001\n",
      "Epoch = 2291 Step =   38303 loss = 0.001\n",
      "Epoch = 2293 Step =   38313 loss = 0.001\n",
      "Epoch = 2295 Step =   38323 loss = 0.001\n",
      "Epoch = 2297 Step =   38333 loss = 0.001\n",
      "Epoch = 2299 Step =   38343 loss = 0.001\n",
      "Epoch = 2301 Step =   38353 loss = 0.001\n",
      "Epoch = 2303 Step =   38363 loss = 0.001\n",
      "Epoch = 2305 Step =   38373 loss = 0.001\n",
      "Epoch = 2307 Step =   38383 loss = 0.001\n",
      "Epoch = 2309 Step =   38393 loss = 0.001\n",
      "Epoch = 2311 Step =   38403 loss = 0.001\n",
      "Epoch = 2313 Step =   38413 loss = 0.001\n",
      "Epoch = 2315 Step =   38423 loss = 0.001\n",
      "Epoch = 2317 Step =   38433 loss = 0.001\n",
      "Epoch = 2319 Step =   38443 loss = 0.001\n",
      "Epoch = 2321 Step =   38453 loss = 0.001\n",
      "Epoch = 2323 Step =   38463 loss = 0.001\n",
      "Epoch = 2325 Step =   38473 loss = 0.001\n",
      "Epoch = 2327 Step =   38483 loss = 0.001\n",
      "Epoch = 2329 Step =   38493 loss = 0.001\n",
      "Epoch = 2331 Step =   38503 loss = 0.001\n",
      "Epoch = 2333 Step =   38513 loss = 0.001\n",
      "Epoch = 2335 Step =   38523 loss = 0.001\n",
      "Epoch = 2337 Step =   38533 loss = 0.001\n",
      "Epoch = 2339 Step =   38543 loss = 0.001\n",
      "Epoch = 2341 Step =   38553 loss = 0.001\n",
      "Epoch = 2343 Step =   38563 loss = 0.001\n",
      "Epoch = 2345 Step =   38573 loss = 0.001\n",
      "Epoch = 2347 Step =   38583 loss = 0.001\n",
      "Epoch = 2349 Step =   38593 loss = 0.001\n",
      "Epoch = 2351 Step =   38603 loss = 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2353 Step =   38613 loss = 0.001\n",
      "Epoch = 2355 Step =   38623 loss = 0.001\n",
      "Epoch = 2357 Step =   38633 loss = 0.001\n",
      "Epoch = 2359 Step =   38643 loss = 0.001\n",
      "Epoch = 2361 Step =   38653 loss = 0.001\n",
      "Epoch = 2363 Step =   38663 loss = 0.001\n",
      "Epoch = 2365 Step =   38673 loss = 0.001\n",
      "Epoch = 2367 Step =   38683 loss = 0.001\n",
      "Epoch = 2369 Step =   38693 loss = 0.001\n",
      "Epoch = 2371 Step =   38703 loss = 0.001\n",
      "Epoch = 2373 Step =   38713 loss = 0.001\n",
      "Epoch = 2375 Step =   38723 loss = 0.001\n",
      "Epoch = 2377 Step =   38733 loss = 0.001\n",
      "Epoch = 2379 Step =   38743 loss = 0.001\n",
      "Epoch = 2381 Step =   38753 loss = 0.001\n",
      "Epoch = 2383 Step =   38763 loss = 0.001\n",
      "Epoch = 2385 Step =   38773 loss = 0.001\n",
      "Epoch = 2387 Step =   38783 loss = 0.001\n",
      "Epoch = 2389 Step =   38793 loss = 0.001\n",
      "Epoch = 2391 Step =   38803 loss = 0.001\n",
      "Epoch = 2393 Step =   38813 loss = 0.001\n",
      "Epoch = 2395 Step =   38823 loss = 0.001\n",
      "Epoch = 2397 Step =   38833 loss = 0.001\n",
      "Epoch = 2399 Step =   38843 loss = 0.001\n",
      "Epoch = 2401 Step =   38853 loss = 0.001\n",
      "Epoch = 2403 Step =   38863 loss = 0.001\n",
      "Epoch = 2405 Step =   38873 loss = 0.001\n",
      "Epoch = 2407 Step =   38883 loss = 0.001\n",
      "Epoch = 2409 Step =   38893 loss = 0.001\n",
      "Epoch = 2411 Step =   38903 loss = 0.001\n",
      "Epoch = 2413 Step =   38913 loss = 0.001\n",
      "Epoch = 2415 Step =   38923 loss = 0.001\n",
      "Epoch = 2417 Step =   38933 loss = 0.001\n",
      "Epoch = 2419 Step =   38943 loss = 0.001\n",
      "Epoch = 2421 Step =   38953 loss = 0.001\n",
      "Epoch = 2423 Step =   38963 loss = 0.001\n",
      "Epoch = 2425 Step =   38973 loss = 0.001\n",
      "Epoch = 2427 Step =   38983 loss = 0.001\n",
      "Epoch = 2429 Step =   38993 loss = 0.001\n",
      "Epoch = 2431 Step =   39003 loss = 0.001\n",
      "Epoch = 2433 Step =   39013 loss = 0.001\n",
      "Epoch = 2435 Step =   39023 loss = 0.001\n",
      "Epoch = 2437 Step =   39033 loss = 0.001\n",
      "Epoch = 2439 Step =   39043 loss = 0.001\n",
      "Epoch = 2441 Step =   39053 loss = 0.001\n",
      "Epoch = 2443 Step =   39063 loss = 0.001\n",
      "Epoch = 2445 Step =   39073 loss = 0.001\n",
      "Epoch = 2447 Step =   39083 loss = 0.001\n",
      "Epoch = 2449 Step =   39093 loss = 0.001\n",
      "Epoch = 2451 Step =   39103 loss = 0.001\n",
      "Epoch = 2453 Step =   39113 loss = 0.001\n",
      "Epoch = 2455 Step =   39123 loss = 0.001\n",
      "Epoch = 2457 Step =   39133 loss = 0.001\n",
      "Epoch = 2459 Step =   39143 loss = 0.001\n",
      "Epoch = 2461 Step =   39153 loss = 0.001\n",
      "Epoch = 2463 Step =   39163 loss = 0.001\n",
      "Epoch = 2465 Step =   39173 loss = 0.001\n",
      "Epoch = 2467 Step =   39183 loss = 0.001\n",
      "Epoch = 2469 Step =   39193 loss = 0.001\n",
      "Epoch = 2471 Step =   39203 loss = 0.001\n",
      "Epoch = 2473 Step =   39213 loss = 0.001\n",
      "Epoch = 2475 Step =   39223 loss = 0.001\n",
      "Epoch = 2477 Step =   39233 loss = 0.001\n",
      "Epoch = 2479 Step =   39243 loss = 0.001\n",
      "Epoch = 2481 Step =   39253 loss = 0.001\n",
      "Epoch = 2483 Step =   39263 loss = 0.001\n",
      "Epoch = 2485 Step =   39273 loss = 0.001\n",
      "Epoch = 2487 Step =   39283 loss = 0.001\n",
      "Epoch = 2489 Step =   39293 loss = 0.001\n",
      "Epoch = 2491 Step =   39303 loss = 0.001\n",
      "Epoch = 2493 Step =   39313 loss = 0.001\n",
      "Epoch = 2495 Step =   39323 loss = 0.001\n",
      "Epoch = 2497 Step =   39333 loss = 0.001\n",
      "Epoch = 2499 Step =   39343 loss = 0.001\n",
      "Epoch = 2502 Step =   39353 loss = 0.001\n",
      "Epoch = 2504 Step =   39363 loss = 0.001\n",
      "Epoch = 2506 Step =   39373 loss = 0.001\n",
      "Epoch = 2508 Step =   39383 loss = 0.001\n",
      "Epoch = 2510 Step =   39393 loss = 0.001\n",
      "Epoch = 2512 Step =   39403 loss = 0.001\n",
      "Epoch = 2514 Step =   39413 loss = 0.001\n",
      "Epoch = 2516 Step =   39423 loss = 0.001\n",
      "Epoch = 2518 Step =   39433 loss = 0.001\n",
      "Epoch = 2520 Step =   39443 loss = 0.001\n",
      "Epoch = 2522 Step =   39453 loss = 0.001\n",
      "Epoch = 2524 Step =   39463 loss = 0.001\n",
      "Epoch = 2526 Step =   39473 loss = 0.001\n",
      "Epoch = 2528 Step =   39483 loss = 0.001\n",
      "Epoch = 2530 Step =   39493 loss = 0.001\n",
      "Epoch = 2532 Step =   39503 loss = 0.001\n",
      "Epoch = 2534 Step =   39513 loss = 0.001\n",
      "Epoch = 2536 Step =   39523 loss = 0.001\n",
      "Epoch = 2538 Step =   39533 loss = 0.001\n",
      "Epoch = 2540 Step =   39543 loss = 0.001\n",
      "Epoch = 2542 Step =   39553 loss = 0.001\n",
      "Epoch = 2544 Step =   39563 loss = 0.001\n",
      "Epoch = 2546 Step =   39573 loss = 0.001\n",
      "Epoch = 2548 Step =   39583 loss = 0.001\n",
      "Epoch = 2550 Step =   39593 loss = 0.001\n",
      "Epoch = 2552 Step =   39603 loss = 0.001\n",
      "Epoch = 2554 Step =   39613 loss = 0.001\n",
      "Epoch = 2556 Step =   39623 loss = 0.001\n",
      "Epoch = 2558 Step =   39633 loss = 0.001\n",
      "Epoch = 2560 Step =   39643 loss = 0.001\n",
      "Epoch = 2562 Step =   39653 loss = 0.001\n",
      "Epoch = 2564 Step =   39663 loss = 0.001\n",
      "Epoch = 2566 Step =   39673 loss = 0.001\n",
      "Epoch = 2568 Step =   39683 loss = 0.001\n",
      "Epoch = 2570 Step =   39693 loss = 0.001\n",
      "Epoch = 2572 Step =   39703 loss = 0.001\n",
      "Epoch = 2574 Step =   39713 loss = 0.001\n",
      "Epoch = 2576 Step =   39723 loss = 0.001\n",
      "Epoch = 2578 Step =   39733 loss = 0.001\n",
      "Epoch = 2580 Step =   39743 loss = 0.001\n",
      "Epoch = 2582 Step =   39753 loss = 0.001\n",
      "Epoch = 2584 Step =   39763 loss = 0.001\n",
      "Epoch = 2586 Step =   39773 loss = 0.001\n",
      "Epoch = 2588 Step =   39783 loss = 0.001\n",
      "Epoch = 2590 Step =   39793 loss = 0.001\n",
      "Epoch = 2592 Step =   39803 loss = 0.001\n",
      "Epoch = 2594 Step =   39813 loss = 0.001\n",
      "Epoch = 2596 Step =   39823 loss = 0.001\n",
      "Epoch = 2598 Step =   39833 loss = 0.001\n",
      "Epoch = 2600 Step =   39843 loss = 0.001\n",
      "Epoch = 2602 Step =   39853 loss = 0.001\n",
      "Epoch = 2604 Step =   39863 loss = 0.001\n",
      "Epoch = 2606 Step =   39873 loss = 0.001\n",
      "Epoch = 2608 Step =   39883 loss = 0.001\n",
      "Epoch = 2610 Step =   39893 loss = 0.001\n",
      "Epoch = 2612 Step =   39903 loss = 0.001\n",
      "Epoch = 2614 Step =   39913 loss = 0.001\n",
      "Epoch = 2616 Step =   39923 loss = 0.001\n",
      "Epoch = 2618 Step =   39933 loss = 0.001\n",
      "Epoch = 2620 Step =   39943 loss = 0.001\n",
      "INFO:tensorflow:Saving checkpoint to path ./trained_models\\model.ckpt\n",
      "Epoch = 2622 Step =   39953 loss = 0.001\n",
      "Epoch = 2624 Step =   39963 loss = 0.001\n",
      "Epoch = 2626 Step =   39973 loss = 0.001\n",
      "Epoch = 2628 Step =   39983 loss = 0.001\n",
      "Epoch = 2630 Step =   39993 loss = 0.001\n",
      "Epoch = 2632 Step =   40003 loss = 0.001\n",
      "Epoch = 2634 Step =   40013 loss = 0.001\n",
      "Epoch = 2636 Step =   40023 loss = 0.001\n",
      "Epoch = 2638 Step =   40033 loss = 0.001\n",
      "Epoch = 2640 Step =   40043 loss = 0.001\n",
      "Epoch = 2642 Step =   40053 loss = 0.001\n",
      "Epoch = 2644 Step =   40063 loss = 0.001\n",
      "Epoch = 2646 Step =   40073 loss = 0.001\n",
      "Epoch = 2648 Step =   40083 loss = 0.001\n",
      "Epoch = 2650 Step =   40093 loss = 0.001\n",
      "Epoch = 2652 Step =   40103 loss = 0.001\n",
      "Epoch = 2654 Step =   40113 loss = 0.001\n",
      "Epoch = 2656 Step =   40123 loss = 0.001\n",
      "Epoch = 2658 Step =   40133 loss = 0.001\n",
      "Epoch = 2660 Step =   40143 loss = 0.001\n",
      "Epoch = 2662 Step =   40153 loss = 0.001\n",
      "Epoch = 2664 Step =   40163 loss = 0.001\n",
      "Epoch = 2666 Step =   40173 loss = 0.001\n",
      "Epoch = 2668 Step =   40183 loss = 0.001\n",
      "Epoch = 2670 Step =   40193 loss = 0.001\n",
      "Epoch = 2672 Step =   40203 loss = 0.001\n",
      "Epoch = 2674 Step =   40213 loss = 0.001\n",
      "Epoch = 2676 Step =   40223 loss = 0.001\n",
      "Epoch = 2678 Step =   40233 loss = 0.001\n",
      "Epoch = 2680 Step =   40243 loss = 0.001\n",
      "Epoch = 2682 Step =   40253 loss = 0.001\n",
      "Epoch = 2684 Step =   40263 loss = 0.001\n",
      "Epoch = 2686 Step =   40273 loss = 0.001\n",
      "Epoch = 2688 Step =   40283 loss = 0.001\n",
      "Epoch = 2690 Step =   40293 loss = 0.001\n",
      "Epoch = 2692 Step =   40303 loss = 0.001\n",
      "Epoch = 2694 Step =   40313 loss = 0.001\n",
      "Epoch = 2696 Step =   40323 loss = 0.001\n",
      "Epoch = 2698 Step =   40333 loss = 0.001\n",
      "Epoch = 2700 Step =   40343 loss = 0.001\n",
      "Epoch = 2702 Step =   40353 loss = 0.001\n",
      "Epoch = 2704 Step =   40363 loss = 0.001\n",
      "Epoch = 2706 Step =   40373 loss = 0.001\n",
      "Epoch = 2708 Step =   40383 loss = 0.001\n",
      "Epoch = 2710 Step =   40393 loss = 0.001\n",
      "Epoch = 2712 Step =   40403 loss = 0.001\n",
      "Epoch = 2714 Step =   40413 loss = 0.001\n",
      "Epoch = 2716 Step =   40423 loss = 0.001\n",
      "Epoch = 2718 Step =   40433 loss = 0.001\n",
      "Epoch = 2720 Step =   40443 loss = 0.001\n",
      "Epoch = 2722 Step =   40453 loss = 0.001\n",
      "Epoch = 2724 Step =   40463 loss = 0.001\n",
      "Epoch = 2726 Step =   40473 loss = 0.001\n",
      "Epoch = 2728 Step =   40483 loss = 0.001\n",
      "Epoch = 2730 Step =   40493 loss = 0.001\n",
      "Epoch = 2732 Step =   40503 loss = 0.001\n",
      "Epoch = 2734 Step =   40513 loss = 0.001\n",
      "Epoch = 2736 Step =   40523 loss = 0.001\n",
      "Epoch = 2738 Step =   40533 loss = 0.001\n",
      "Epoch = 2740 Step =   40543 loss = 0.001\n",
      "Epoch = 2742 Step =   40553 loss = 0.001\n",
      "Epoch = 2744 Step =   40563 loss = 0.001\n",
      "Epoch = 2746 Step =   40573 loss = 0.001\n",
      "Epoch = 2748 Step =   40583 loss = 0.001\n",
      "Epoch = 2750 Step =   40593 loss = 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2752 Step =   40603 loss = 0.001\n",
      "Epoch = 2754 Step =   40613 loss = 0.001\n",
      "Epoch = 2756 Step =   40623 loss = 0.001\n",
      "Epoch = 2758 Step =   40633 loss = 0.001\n",
      "Epoch = 2760 Step =   40643 loss = 0.001\n",
      "Epoch = 2762 Step =   40653 loss = 0.001\n",
      "Epoch = 2764 Step =   40663 loss = 0.001\n",
      "Epoch = 2766 Step =   40673 loss = 0.001\n",
      "Epoch = 2768 Step =   40683 loss = 0.001\n",
      "Epoch = 2770 Step =   40693 loss = 0.001\n",
      "Epoch = 2772 Step =   40703 loss = 0.001\n",
      "Epoch = 2774 Step =   40713 loss = 0.001\n",
      "Epoch = 2776 Step =   40723 loss = 0.001\n",
      "Epoch = 2778 Step =   40733 loss = 0.001\n",
      "Epoch = 2780 Step =   40743 loss = 0.001\n",
      "Epoch = 2782 Step =   40753 loss = 0.001\n",
      "Epoch = 2784 Step =   40763 loss = 0.001\n",
      "Epoch = 2786 Step =   40773 loss = 0.001\n",
      "Epoch = 2788 Step =   40783 loss = 0.001\n",
      "Epoch = 2790 Step =   40793 loss = 0.001\n",
      "Epoch = 2792 Step =   40803 loss = 0.001\n",
      "Epoch = 2794 Step =   40813 loss = 0.001\n",
      "Epoch = 2796 Step =   40823 loss = 0.001\n",
      "Epoch = 2798 Step =   40833 loss = 0.001\n",
      "Epoch = 2800 Step =   40843 loss = 0.001\n",
      "Epoch = 2802 Step =   40853 loss = 0.001\n",
      "Epoch = 2804 Step =   40863 loss = 0.001\n",
      "Epoch = 2806 Step =   40873 loss = 0.001\n",
      "Epoch = 2808 Step =   40883 loss = 0.001\n",
      "Epoch = 2810 Step =   40893 loss = 0.001\n",
      "Epoch = 2812 Step =   40903 loss = 0.001\n",
      "Epoch = 2814 Step =   40913 loss = 0.001\n",
      "Epoch = 2816 Step =   40923 loss = 0.001\n",
      "Epoch = 2818 Step =   40933 loss = 0.001\n",
      "Epoch = 2820 Step =   40943 loss = 0.001\n",
      "Epoch = 2822 Step =   40953 loss = 0.001\n",
      "Epoch = 2824 Step =   40963 loss = 0.001\n",
      "Epoch = 2826 Step =   40973 loss = 0.001\n",
      "Epoch = 2828 Step =   40983 loss = 0.001\n",
      "Epoch = 2830 Step =   40993 loss = 0.001\n",
      "Epoch = 2832 Step =   41003 loss = 0.001\n",
      "Epoch = 2834 Step =   41013 loss = 0.001\n",
      "Epoch = 2836 Step =   41023 loss = 0.001\n",
      "Epoch = 2838 Step =   41033 loss = 0.001\n",
      "Epoch = 2840 Step =   41043 loss = 0.001\n",
      "Epoch = 2842 Step =   41053 loss = 0.001\n",
      "Epoch = 2844 Step =   41063 loss = 0.001\n",
      "Epoch = 2846 Step =   41073 loss = 0.001\n",
      "Epoch = 2848 Step =   41083 loss = 0.001\n",
      "Epoch = 2850 Step =   41093 loss = 0.001\n",
      "Epoch = 2852 Step =   41103 loss = 0.001\n",
      "Epoch = 2854 Step =   41113 loss = 0.001\n",
      "Epoch = 2856 Step =   41123 loss = 0.001\n",
      "Epoch = 2858 Step =   41133 loss = 0.001\n",
      "Epoch = 2860 Step =   41143 loss = 0.001\n",
      "Epoch = 2862 Step =   41153 loss = 0.001\n",
      "Epoch = 2864 Step =   41163 loss = 0.001\n",
      "Epoch = 2866 Step =   41173 loss = 0.001\n",
      "Epoch = 2868 Step =   41183 loss = 0.001\n",
      "Epoch = 2870 Step =   41193 loss = 0.001\n",
      "Epoch = 2872 Step =   41203 loss = 0.001\n",
      "Epoch = 2874 Step =   41213 loss = 0.001\n",
      "Epoch = 2876 Step =   41223 loss = 0.001\n",
      "Epoch = 2878 Step =   41233 loss = 0.001\n",
      "Epoch = 2880 Step =   41243 loss = 0.001\n",
      "Epoch = 2882 Step =   41253 loss = 0.001\n",
      "Epoch = 2884 Step =   41263 loss = 0.001\n",
      "Epoch = 2886 Step =   41273 loss = 0.001\n",
      "Epoch = 2888 Step =   41283 loss = 0.001\n",
      "Epoch = 2890 Step =   41293 loss = 0.001\n",
      "Epoch = 2892 Step =   41303 loss = 0.001\n",
      "Epoch = 2894 Step =   41313 loss = 0.001\n",
      "Epoch = 2896 Step =   41323 loss = 0.001\n",
      "Epoch = 2898 Step =   41333 loss = 0.001\n",
      "Epoch = 2900 Step =   41343 loss = 0.001\n",
      "Epoch = 2902 Step =   41353 loss = 0.001\n",
      "Epoch = 2904 Step =   41363 loss = 0.001\n",
      "Epoch = 2906 Step =   41373 loss = 0.001\n",
      "Epoch = 2908 Step =   41383 loss = 0.001\n",
      "Epoch = 2910 Step =   41393 loss = 0.001\n",
      "Epoch = 2912 Step =   41403 loss = 0.001\n",
      "Epoch = 2914 Step =   41413 loss = 0.001\n",
      "Epoch = 2916 Step =   41423 loss = 0.001\n",
      "Epoch = 2918 Step =   41433 loss = 0.001\n",
      "Epoch = 2920 Step =   41443 loss = 0.001\n",
      "Epoch = 2922 Step =   41453 loss = 0.001\n",
      "Epoch = 2924 Step =   41463 loss = 0.001\n",
      "Epoch = 2926 Step =   41473 loss = 0.001\n",
      "Epoch = 2928 Step =   41483 loss = 0.001\n",
      "Epoch = 2930 Step =   41493 loss = 0.001\n",
      "Epoch = 2932 Step =   41503 loss = 0.001\n",
      "Epoch = 2934 Step =   41513 loss = 0.001\n",
      "Epoch = 2936 Step =   41523 loss = 0.001\n",
      "Epoch = 2938 Step =   41533 loss = 0.001\n",
      "Epoch = 2940 Step =   41543 loss = 0.001\n",
      "Epoch = 2942 Step =   41553 loss = 0.001\n",
      "Epoch = 2944 Step =   41563 loss = 0.001\n",
      "Epoch = 2946 Step =   41573 loss = 0.001\n",
      "Epoch = 2948 Step =   41583 loss = 0.001\n",
      "Epoch = 2950 Step =   41593 loss = 0.001\n",
      "Epoch = 2952 Step =   41603 loss = 0.001\n",
      "Epoch = 2954 Step =   41613 loss = 0.001\n",
      "Epoch = 2956 Step =   41623 loss = 0.001\n",
      "Epoch = 2958 Step =   41633 loss = 0.001\n",
      "Epoch = 2960 Step =   41643 loss = 0.001\n",
      "Epoch = 2962 Step =   41653 loss = 0.001\n",
      "Epoch = 2964 Step =   41663 loss = 0.001\n",
      "Epoch = 2966 Step =   41673 loss = 0.001\n",
      "Epoch = 2968 Step =   41683 loss = 0.001\n",
      "Epoch = 2970 Step =   41693 loss = 0.001\n",
      "Epoch = 2972 Step =   41703 loss = 0.001\n",
      "Epoch = 2974 Step =   41713 loss = 0.001\n",
      "Epoch = 2976 Step =   41723 loss = 0.001\n",
      "Epoch = 2978 Step =   41733 loss = 0.001\n",
      "Epoch = 2980 Step =   41743 loss = 0.001\n",
      "Epoch = 2982 Step =   41753 loss = 0.001\n",
      "Epoch = 2984 Step =   41763 loss = 0.001\n",
      "Epoch = 2986 Step =   41773 loss = 0.001\n",
      "Epoch = 2988 Step =   41783 loss = 0.001\n",
      "Epoch = 2990 Step =   41793 loss = 0.001\n",
      "Epoch = 2992 Step =   41803 loss = 0.001\n",
      "Epoch = 2994 Step =   41813 loss = 0.001\n",
      "Epoch = 2996 Step =   41823 loss = 0.001\n",
      "Epoch = 2998 Step =   41833 loss = 0.001\n",
      "Epoch = 3000 Step =   41843 loss = 0.001\n",
      "Training is done.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_models\\model.ckpt-39944\n",
      "INFO:tensorflow:Froze 7 variables.\n",
      "INFO:tensorflow:Converted 7 variables to const ops.\n",
      "3748 ops in the final graph.\n",
      "0.256519\n",
      "OBJ 0\n"
     ]
    }
   ],
   "source": [
    "train_id_data, token_vocab, target_vocab = load_data()#데이터 로드\n",
    "num_vocabs       = token_vocab.get_num_tokens()#vocab로드\n",
    "num_target_class = target_vocab.get_num_targets()#타겟(카테고리) 로드\n",
    "\n",
    "train(train_id_data, num_vocabs, num_target_class)#학습\n",
    "predict(token_vocab, target_vocab, \"별로에요\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992915\n",
      "POS 0\n"
     ]
    }
   ],
   "source": [
    "predict(token_vocab, target_vocab, \"맛은 괜찮지만 서비스가 별로에요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "POS 1\n"
     ]
    }
   ],
   "source": [
    "predict(token_vocab, target_vocab, \"재료가 정말 신선하고 좋아요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "POS 0\n",
      "0.999628\n",
      "OBJ 0\n"
     ]
    }
   ],
   "source": [
    "predict(token_vocab, target_vocab, \"너무 더워서 찝찝해\")\n",
    "predict(token_vocab, target_vocab, \"지구는 둥글다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999876\n",
      "POS 0\n"
     ]
    }
   ],
   "source": [
    "predict(token_vocab, target_vocab, \"회의 결과는 성공적이었습니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "POS 0\n",
      "1.0\n",
      "POS 1\n",
      "0.999869\n",
      "POS 0\n",
      "0.994909\n",
      "NEG 0\n",
      "0.99915\n",
      "POS 0\n",
      "0.999994\n",
      "POS 0\n"
     ]
    }
   ],
   "source": [
    "predict(token_vocab, target_vocab, \"욕실도 널찍하고, 아메니티도 충실히 구비되어 있습니다.\")\n",
    "predict(token_vocab, target_vocab, \"집을 떠나 왔지만, 집처럼 편한 곳입니다.\")\n",
    "predict(token_vocab, target_vocab, \"일단 아침식사 메뉴가 풍부해서 놀랐습니다.\")\n",
    "predict(token_vocab, target_vocab, \"윗층은 옆 건물이 낮아서 전망이 좋습니다.\")\n",
    "predict(token_vocab, target_vocab, \"와이프와 저는 파리에 있는 이 아담하고 고급스런 호텔에서 며칠을 보냈습니다.\")\n",
    "predict(token_vocab, target_vocab, \"일부러 편리한 곳을 찾아서 발견한 비지니스 호텔은 아니었지만 실제로 가야바쵸 역에서도 가까워 편리했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999999\n",
      "NEG 0\n"
     ]
    }
   ],
   "source": [
    "predict(token_vocab, target_vocab, \"레스토랑이 너무음식 가지러 가기 힘들었습니다. 넓어서 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
